{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/MattRamb97/Erasmus_Hardgainers/blob/main/Recipes_model_v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QgSEjO0i7e_v"
   },
   "source": [
    "**RECIPES MODEL**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7EArwz7S8MEf"
   },
   "source": [
    "We utilized the URLs provided to access the datasets stored in the folder https://raw.githubusercontent.com/MattRamb97/Erasmus_Hardgainers/main/Datasets/\n",
    "\n",
    "using the pandas library. Subsequently, we identified an issue in the 'ingredients' column of the three datasets, characterized by the presence of the word 'ADVERTISEMENT', which we proceeded to remove. Additionally, we printed information regarding one of the datasets (the same information applies to the others) and their respective shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zORKNY3QbWaP",
    "outputId": "be36e788-d367-48e9-a1c0-1a35fe2336de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 39802 entries, rmK12Uau.ntP510KeImX506H6Mr6jTu to 2Q3Zpfgt/PUwn1YABjJ5A9T3ZW8xwVa\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   title         39522 non-null  object\n",
      " 1   ingredients   39522 non-null  object\n",
      " 2   instructions  39522 non-null  object\n",
      " 3   picture_link  39522 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 2.5+ MB\n",
      "\n",
      "From AR: (39522, 4)\n"
     ]
    }
   ],
   "source": [
    "url_1 = 'https://raw.githubusercontent.com/MattRamb97/Erasmus_Hardgainers/main/Datasets/recipes_raw_nosource_ar.json'\n",
    "\n",
    "import pandas as pd\n",
    "import sys\n",
    "df_ar = pd.read_json(url_1, orient='records', dtype='dict').transpose()\n",
    "df_ar.info()\n",
    "print()\n",
    "\n",
    "df_ar = df_ar.dropna(subset=['title', 'ingredients', 'instructions', 'picture_link'])\n",
    "\n",
    "df_ar['title'] = df_ar['title'].astype(str)\n",
    "\n",
    "df_ar['ingredients'] = df_ar['ingredients'].astype(str).str.replace('ADVERTISEMENT', '',regex=True)\n",
    "\n",
    "# Safely evaluate the 'ingredients' column\n",
    "def safe_eval(x):\n",
    "    try:\n",
    "        return ', '.join(eval(x))\n",
    "    except:\n",
    "        return ''  # Return an empty string in case of an error\n",
    "\n",
    "df_ar['ingredients'] = df_ar['ingredients'].apply(safe_eval)\n",
    "\n",
    "df_ar['instructions'] = df_ar['instructions'].astype(str)\n",
    "\n",
    "print('From AR:', df_ar.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s6mJc7q2TC5S"
   },
   "source": [
    "Cleaning of the ingredients from numbers, units of measure and ( , ) , /"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cZUHZoddMr1E",
    "outputId": "2098fc0d-2939-426f-e960-9ca9784dbd2f"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_ingredients(ingredient):\n",
    "    # Define the pattern to remove numbers, common units of measure, and unwanted characters including non-standard spaces\n",
    "    pattern = r'\\b\\d+\\.?\\d*|\\b(?:oz|ounce|ounces|lb|pound|pounds|g|gram|grams|kg|kilogram|kilograms|ml|milliliter|milliliters|l|liter|liters|tbsp|tbs|tablespoon|tablespoons|tsp|teaspoon|teaspoons|cup|cups|pinch|pinches)\\b|[()\\/]'\n",
    "    # Replace the matched items with nothing (effectively removing them)\n",
    "    cleaned_ingredient = re.sub(pattern, '', ingredient, flags=re.IGNORECASE)\n",
    "    # Remove any kind of space-like characters and trim the string\n",
    "    cleaned_ingredient = re.sub(r'\\s+', ' ', cleaned_ingredient).strip()\n",
    "    # Remove any invisible characters or non-breaking spaces\n",
    "    cleaned_ingredient = re.sub(r'[\\u200B-\\u200D\\uFEFF]', '', cleaned_ingredient)\n",
    "    return cleaned_ingredient\n",
    "\n",
    "# Apply the cleaning function to the ingredients column\n",
    "df_ar['ingredients'] = df_ar['ingredients'].apply(clean_ingredients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3GcEDJTI-KL4"
   },
   "source": [
    "We cleaned the three datasets using two function:\n",
    "- uncontract(): expands contracted words commonly found in English sentences into their full forms using regular expressions.\n",
    "- clean_recepies(): removes non-alphanumeric characters from the input text except for spaces and hyphens. It then replaces multiple spaces and hyphens with a single space and normalizes units of measurement (e.g., cups, tablespoons) by removing them. Next, it removes numerical digits, assuming they represent quantities. Finally, it normalizes whitespace by removing extra spaces and ensuring consistent spacing between words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fGLa2UZXF9g6",
    "outputId": "6521e95a-1fb4-4099-fb13-827cc35c4c3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (0.31.0.dev0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from accelerate) (1.26.4)\n",
      "Requirement already satisfied: huggingface-hub in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from accelerate) (0.23.0)\n",
      "Requirement already satisfied: pyyaml in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from accelerate) (2.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from accelerate) (24.0)\n",
      "Requirement already satisfied: psutil in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from accelerate) (5.9.8)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from accelerate) (0.4.3)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
      "Requirement already satisfied: networkx in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.3)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
      "Requirement already satisfied: fsspec in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2024.3.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2.20.5)\n",
      "Requirement already satisfied: triton==2.3.0 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
      "Requirement already satisfied: sympy in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.11.0)\n",
      "Requirement already satisfied: filelock in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.14.0)\n",
      "Requirement already satisfied: jinja2 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: requests in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2.2.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple/\n",
      "Requirement already satisfied: bitsandbytes in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (0.43.1)\n",
      "Requirement already satisfied: numpy in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from bitsandbytes) (1.26.4)\n",
      "Requirement already satisfied: torch in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from bitsandbytes) (2.3.0)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch->bitsandbytes) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch->bitsandbytes) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch->bitsandbytes) (2.20.5)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch->bitsandbytes) (11.0.2.54)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch->bitsandbytes) (4.11.0)\n",
      "Requirement already satisfied: filelock in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch->bitsandbytes) (3.14.0)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch->bitsandbytes) (8.9.2.26)\n",
      "Requirement already satisfied: fsspec in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch->bitsandbytes) (2024.3.1)\n",
      "Requirement already satisfied: networkx in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch->bitsandbytes) (3.3)\n",
      "Requirement already satisfied: triton==2.3.0 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch->bitsandbytes) (2.3.0)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: sympy in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch->bitsandbytes) (1.12)\n",
      "Requirement already satisfied: jinja2 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch->bitsandbytes) (3.1.3)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from jinja2->torch->bitsandbytes) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from sympy->torch->bitsandbytes) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install accelerate\n",
    "!pip install -i https://pypi.org/simple/ bitsandbytes\n",
    "!pip install -q -U git+https://github.com/huggingface/transformers.git\n",
    "!pip install -q -U git+https://github.com/huggingface/peft.git\n",
    "!pip install -q -U git+https://github.com/huggingface/accelerate.git\n",
    "!pip install -q -U datasets scipy ipywidgets matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MhNc7-SuHIUc"
   },
   "source": [
    "Create a formatting_func to structure training examples as prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "iP0ZOpuRGbb8"
   },
   "outputs": [],
   "source": [
    "def formatting_func(ingredients, title, instructions):\n",
    "    text = f\"### Ingredients: {ingredients}\\n### Generate Title and Instructions:\\n### Title:{title}\\n### Instructions: {instructions}\"\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2dXRlDN-HM-U"
   },
   "source": [
    "Load Mistral - mistralai/Mistral-7B-v0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408,
     "referenced_widgets": [
      "908522ef9bd94e6f8a02e4642ee38a0c",
      "d8ce7a5f583f4fb7948614b68fd31404",
      "6640c21d6b354e1fb37300e965bd062d",
      "f24c5e848078403db2719e2c13c26f3d",
      "58c64e0d7d764deb9a80ee6ab8a0be95",
      "80b02623217c4864a5802c1215d92f5a",
      "a32c582e23e44efb86d9ab2203e7525f",
      "efdb470c4faf447e8fb73326da34a641",
      "8688af750cff4c9885fdf03c322b579b",
      "2d7614b2f7164f63bd78dc5de95ea1ff",
      "23e56508698148a396955a35b8feb7da"
     ]
    },
    "id": "I_MSkGl3UOiw",
    "outputId": "279d1f3d-0889-443c-a6f7-5742023404a9"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "399b37fcbc9a4f009107e4d5c164dac3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7c8e07164f143ceb3246b89e172436f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "base_model_id = \"mistralai/Mistral-7B-v0.1\"\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(base_model_id, quantization_config=bnb_config, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uh_eFIQ4IEYS"
   },
   "source": [
    "Set up the tokenizer. Add padding on the left as it makes training use less memory. For model_max_length, it's helpful to get a distribution of your data lengths. Let's first tokenize without the truncation/padding, so we can get a length distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "SrALxLNtILcT"
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    base_model_id,\n",
    "    padding_side=\"left\",\n",
    "    add_eos_token=True,\n",
    "    add_bos_token=True,\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "def generate_and_tokenize_prompt(ingredients, title, instructions):\n",
    "    return tokenizer(formatting_func(ingredients, title, instructions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6qxSioghIXcp"
   },
   "source": [
    "Reformat the prompt and tokenize each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Efy3OWxtIbNy"
   },
   "outputs": [],
   "source": [
    "tokenized_titles = []\n",
    "tokenized_ingredients = []\n",
    "tokenized_instructions = []\n",
    "\n",
    "for ingredients, title, instructions in zip(df_ar['ingredients'].iloc[:1000], df_ar['title'].iloc[:1000], df_ar['instructions'].iloc[:1000]):\n",
    "    tokenized_ingredients.append(generate_and_tokenize_prompt( ingredients,title,instructions))\n",
    "    tokenized_titles.append(generate_and_tokenize_prompt( ingredients,title, instructions))\n",
    "    tokenized_instructions.append(generate_and_tokenize_prompt( ingredients,title, instructions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_1v-yvq2KZDG"
   },
   "source": [
    "Let's get a distribution of our dataset lengths, so we can determine the appropriate max_length for our input tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 581
    },
    "id": "sc9oNJ75KZwZ",
    "outputId": "297bd40e-a400-47df-dcd4-9c652120ccd6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_data_lengths(tokenized_titles, tokenized_ingredients):\n",
    "    lengths = [len(x['input_ids']) for x in tokenized_titles]\n",
    "    lengths += [len(x['input_ids']) for x in tokenized_ingredients]\n",
    "    print(len(lengths))\n",
    "\n",
    "    # Plotting the histogram\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(lengths, bins=20, alpha=0.7, color='blue')\n",
    "    plt.xlabel('Length of input_ids')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Distribution of Lengths of input_ids')\n",
    "    plt.show()\n",
    "\n",
    "plot_data_lengths(tokenized_titles, tokenized_ingredients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ZbTte5073fEL"
   },
   "outputs": [],
   "source": [
    "max_length = 365  # This was an appropriate max length for my dataset\n",
    "\n",
    "def generate_and_tokenize_prompt2(ingredients, title, instructions):\n",
    "\n",
    "    ingredients_result = tokenizer(\n",
    "        ingredients,\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    title_result = tokenizer(\n",
    "        title,\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    instructions_result = tokenizer(\n",
    "        instructions,\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    ingredients_result[\"labels\"] = ingredients_result[\"input_ids\"].copy()\n",
    "    title_result[\"labels\"] = title_result[\"input_ids\"].copy()\n",
    "    instructions_result[\"labels\"] = title_result[\"input_ids\"].copy()\n",
    "\n",
    "    return ingredients_result, title_result, instructions_result\n",
    "\n",
    "# Tokenization of the dataset\n",
    "tokenized_data = []\n",
    "for ingredients, title, instructions in zip(df_ar['ingredients'].iloc[:5000], df_ar['title'].iloc[:5000], df_ar['instructions'].iloc[:5000]):\n",
    "    ingredients_result, title_result, instructions_result = generate_and_tokenize_prompt2(ingredients, title, instructions)\n",
    "    # Concatenating results into a single input\n",
    "    combined_input_ids = ingredients_result[\"input_ids\"] + title_result[\"input_ids\"] + instructions_result[\"input_ids\"]\n",
    "    combined_labels = ingredients_result[\"labels\"] + title_result[\"labels\"] +  instructions_result[\"labels\"]\n",
    "    tokenized_data.append({'input_ids': combined_input_ids, 'labels': combined_labels})\n",
    "\n",
    "# Split data into training and evaluation datasets\n",
    "split_index = int(0.8 * len(tokenized_data))\n",
    "train_dataset = tokenized_data[:split_index]\n",
    "eval_dataset = tokenized_data[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fke7hj1JPyQT",
    "outputId": "5e5ca835-3aa1-4af6-9950-e7481f0c856b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Ingredients: warm water degrees F degrees C , . packages active dry yeast , honey , bread flour , butter, melted , honey , salt , whole wheat flour , butter, melted ,\n",
      "### Generate Title and Instructions:\n",
      "### Title: Honey Wheat Bread\n",
      "### Instructions:\n",
      "1. In a large bowl, dissolve the yeast in 2 cups of warm water (105 to 115 degrees F). Add the honey and stir until it is completely dissolved. Mix in 4 cups of white flour, one cup at a time. Beat well after each addition. Stir in the melted butter.\n",
      "2. Turn dough out onto a floured surface and knead for about 8 minutes, or until smooth and elastic. Place in a greased bowl, cover with plastic wrap and let rise in a warm place until doubled in size, about 1 hour. Punch down dough and turn it out onto a lightly floured surface. Knead in enough whole wheat flour to make a stiff dough. Cover and let rest for 10 minutes.\n",
      "3. Divide dough into two equal pieces. Shape each piece into a loaf and place in two greased 9x5 inch loaf pans. Cover and let rise until doubled, about 45 minutes. Preheat oven to 375 degrees F (190 degrees C).\n",
      "4. Bake for 30 minutes\n"
     ]
    }
   ],
   "source": [
    "eval_prompt = f\"### Ingredients: {df_ar['ingredients'].iloc[265]}\\n### Generate Title and Instructions:\\n### Title:\"\n",
    "\n",
    "# Init an eval tokenizer that doesn't add padding or eos token\n",
    "eval_tokenizer = AutoTokenizer.from_pretrained(\n",
    "    base_model_id,\n",
    "    add_bos_token=True,\n",
    ")\n",
    "\n",
    "model_input = eval_tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    print(eval_tokenizer.decode(model.generate(**model_input, max_new_tokens=256, repetition_penalty=1.15)[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k4qY_S0EaOPs"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JMDv9mCeV-il"
   },
   "source": [
    "**Set Up LoRA**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "txXs94_zWCcQ"
   },
   "source": [
    "Now, to start our fine-tuning, we have to apply some preprocessing to the model to prepare it for training. For that use the prepare_model_for_kbit_training method from PEFT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "k-rUo6KTWFMU"
   },
   "outputs": [],
   "source": [
    "from peft import prepare_model_for_kbit_training\n",
    "\n",
    "model.gradient_checkpointing_enable()\n",
    "model = prepare_model_for_kbit_training(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "JTws6uDbWIOD"
   },
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YMHP0xk-WNVV"
   },
   "source": [
    "Let's print the model to examine its layers, as we will apply QLoRA to all the linear layers of the model. Those layers are q_proj, k_proj, v_proj, o_proj, gate_proj, up_proj, down_proj, and lm_head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z-6Iqd0KYCID",
    "outputId": "a0569bd1-2358-4f92-c5f8-336286a831be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MistralForCausalLM(\n",
      "  (model): MistralModel(\n",
      "    (embed_tokens): Embedding(32000, 4096)\n",
      "    (layers): ModuleList(\n",
      "      (0-31): 32 x MistralDecoderLayer(\n",
      "        (self_attn): MistralSdpaAttention(\n",
      "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): MistralRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): MistralMLP(\n",
      "          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): MistralRMSNorm()\n",
      "        (post_attention_layernorm): MistralRMSNorm()\n",
      "      )\n",
      "    )\n",
      "    (norm): MistralRMSNorm()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d13VfHnQYHw5"
   },
   "source": [
    "Here we define the LoRA config.\n",
    "\n",
    "r is the rank of the low-rank matrix used in the adapters, which thus controls the number of parameters trained. A higher rank will allow for more expressivity, but there is a compute tradeoff.\n",
    "\n",
    "alpha is the scaling factor for the learned weights. The weight matrix is scaled by alpha/r, and thus a higher value for alpha assigns more weight to the LoRA activations.\n",
    "\n",
    "The values used in the QLoRA paper were r=64 and lora_alpha=16, and these are said to generalize well, but we will use r=32 and lora_alpha=64 so that we have more emphasis on the new fine-tuned data while also reducing computational complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yvugWrLvYPZU",
    "outputId": "ac8a27cb-5ca3-4d55-ba69-7a1418a6f90a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 85041152 || all params: 3837112320 || trainable%: 2.2162799758751914\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "config = LoraConfig(\n",
    "    r=32,\n",
    "    lora_alpha=64,\n",
    "    target_modules=[\n",
    "        \"q_proj\",\n",
    "        \"k_proj\",\n",
    "        \"v_proj\",\n",
    "        \"o_proj\",\n",
    "        \"gate_proj\",\n",
    "        \"up_proj\",\n",
    "        \"down_proj\",\n",
    "        \"lm_head\",\n",
    "    ],\n",
    "    bias=\"none\",\n",
    "    lora_dropout=0.05,  # Conventional\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, config)\n",
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4xhf8d0LYUdD"
   },
   "source": [
    "See how the model looks different now, with the LoRA adapters added:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v6y9Rys9YWey",
    "outputId": "95594d1f-6562-4cb6-a152-8da3f24cf272"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeftModelForCausalLM(\n",
      "  (base_model): LoraModel(\n",
      "    (model): MistralForCausalLM(\n",
      "      (model): MistralModel(\n",
      "        (embed_tokens): Embedding(32000, 4096)\n",
      "        (layers): ModuleList(\n",
      "          (0-31): 32 x MistralDecoderLayer(\n",
      "            (self_attn): MistralSdpaAttention(\n",
      "              (q_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (k_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=1024, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (v_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=1024, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (o_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (rotary_emb): MistralRotaryEmbedding()\n",
      "            )\n",
      "            (mlp): MistralMLP(\n",
      "              (gate_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=14336, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (up_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=14336, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (down_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=14336, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (act_fn): SiLU()\n",
      "            )\n",
      "            (input_layernorm): MistralRMSNorm()\n",
      "            (post_attention_layernorm): MistralRMSNorm()\n",
      "          )\n",
      "        )\n",
      "        (norm): MistralRMSNorm()\n",
      "      )\n",
      "      (lm_head): lora.Linear(\n",
      "        (base_layer): Linear(in_features=4096, out_features=32000, bias=False)\n",
      "        (lora_dropout): ModuleDict(\n",
      "          (default): Dropout(p=0.05, inplace=False)\n",
      "        )\n",
      "        (lora_A): ModuleDict(\n",
      "          (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "        )\n",
      "        (lora_B): ModuleDict(\n",
      "          (default): Linear(in_features=32, out_features=32000, bias=False)\n",
      "        )\n",
      "        (lora_embedding_A): ParameterDict()\n",
      "        (lora_embedding_B): ParameterDict()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tIu5yNhYaRmq"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nkBAVmb3ZZ6e"
   },
   "source": [
    "**TRAINING LoRA MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "PGTxRTgLZi_0"
   },
   "outputs": [],
   "source": [
    "if torch.cuda.device_count() > 1: # If more than 1 GPU\n",
    "    model.is_parallelizable = True\n",
    "    model.model_parallel = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "J4Nh-UgTZktM"
   },
   "outputs": [],
   "source": [
    "from accelerate import FullyShardedDataParallelPlugin, Accelerator\n",
    "from torch.distributed.fsdp.fully_sharded_data_parallel import FullOptimStateDictConfig, FullStateDictConfig\n",
    "\n",
    "fsdp_plugin = FullyShardedDataParallelPlugin(\n",
    "    state_dict_config=FullStateDictConfig(offload_to_cpu=True, rank0_only=False),\n",
    "    optim_state_dict_config=FullOptimStateDictConfig(offload_to_cpu=True, rank0_only=False),\n",
    ")\n",
    "\n",
    "accelerator = Accelerator(fsdp_plugin=fsdp_plugin)\n",
    "\n",
    "model = accelerator.prepare_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_QY-O7nOa3AZ",
    "outputId": "f4ace141-0cdd-431c-dabf-b9a490e52185"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmatteo-rambaldi\u001b[0m (\u001b[33mrecipes_model\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "!pip install -q wandb -U\n",
    "\n",
    "import wandb, os\n",
    "wandb.login()\n",
    "\n",
    "wandb_project = \"journal-finetune\"\n",
    "if len(wandb_project) > 0:\n",
    "    os.environ[\"WANDB_PROJECT\"] = wandb_project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 974
    },
    "id": "BeEHSdGmZyjQ",
    "outputId": "12c8bf03-2316-4a2a-c40d-96655b66fe2d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/transformers/training_args.py:1463: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/verb-workspace/wandb/run-20240506_112154-fvc9ghxl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/recipes_model/journal-finetune/runs/fvc9ghxl' target=\"_blank\">mistral-recepies-model_v4-2024-05-06-11-21</a></strong> to <a href='https://wandb.ai/recipes_model/journal-finetune' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/recipes_model/journal-finetune' target=\"_blank\">https://wandb.ai/recipes_model/journal-finetune</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/recipes_model/journal-finetune/runs/fvc9ghxl' target=\"_blank\">https://wandb.ai/recipes_model/journal-finetune/runs/fvc9ghxl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 1:26:02, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>3.229200</td>\n",
       "      <td>1.079165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.995400</td>\n",
       "      <td>0.992337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.984100</td>\n",
       "      <td>0.961145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.956700</td>\n",
       "      <td>0.948034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.958100</td>\n",
       "      <td>0.940715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.873100</td>\n",
       "      <td>0.932555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.843000</td>\n",
       "      <td>0.929684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.882400</td>\n",
       "      <td>0.919526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.885900</td>\n",
       "      <td>0.913028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.897200</td>\n",
       "      <td>0.908335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.842200</td>\n",
       "      <td>0.905699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.904200</td>\n",
       "      <td>0.900052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.869200</td>\n",
       "      <td>0.900750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.857100</td>\n",
       "      <td>0.895033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.815600</td>\n",
       "      <td>0.892952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.802900</td>\n",
       "      <td>0.890279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.851500</td>\n",
       "      <td>0.888162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.826500</td>\n",
       "      <td>0.886389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.867800</td>\n",
       "      <td>0.885266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.807300</td>\n",
       "      <td>0.884654</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=500, training_loss=0.9974670066833496, metrics={'train_runtime': 5168.2276, 'train_samples_per_second': 0.193, 'train_steps_per_second': 0.097, 'total_flos': 4.727575719936e+16, 'train_loss': 0.9974670066833496, 'epoch': 0.25})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from datetime import datetime\n",
    "import torch\n",
    "\n",
    "project = \"recepies-model_v3\"\n",
    "base_model_name = \"mistral\"\n",
    "run_name = base_model_name + \"-\" + project\n",
    "output_dir = \"./\" + run_name\n",
    "\n",
    "# Initialize Trainer with your model and tokenizer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=TrainingArguments(\n",
    "        output_dir='./output',\n",
    "        warmup_steps=1,\n",
    "        per_device_train_batch_size=2,\n",
    "        gradient_accumulation_steps=1,\n",
    "        gradient_checkpointing=True,\n",
    "        max_steps=500,\n",
    "        learning_rate=2.5e-5,\n",
    "        fp16=True,\n",
    "        optim=\"paged_adamw_8bit\",\n",
    "        logging_steps=25,\n",
    "        logging_dir=\"./logs\",\n",
    "        save_strategy=\"steps\",\n",
    "        save_steps=25,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        eval_steps=25,\n",
    "        do_eval=True,\n",
    "        report_to=\"wandb\",\n",
    "        run_name=f\"{run_name}-{datetime.now().strftime('%Y-%m-%d-%H-%M')}\"\n",
    "    ),\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
    ")\n",
    "model.config.use_cache = False\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17,
     "referenced_widgets": [
      "ccc1bd2c0a454f96bd2fc895043dde0f",
      "6c7723b53aa749cf93987e4e5fa1da32",
      "ce0066c99ea64879b679fb68afe2e47d",
      "3fc14a395f1d4569865cbeea819c42c6",
      "5f2a769a466e4c8ebed1b5eb555390cb",
      "9b238e7f08264805b524ac3100444476",
      "7afe9062140a45099f85e96d07db9a27",
      "ed6210d9752348ab9478e527c28c3c2b",
      "3c8da0d7d977480daec405cbd81ce475",
      "f711cc2c2590496eb21e79a64e16660f",
      "e3eb380a732c4ac4aa897968f546f1c8"
     ]
    },
    "id": "2pHEKwMW4Y9K",
    "outputId": "3cdba9a4-bb89-4043-b33b-f99d7aeadcaf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "763d58fd554843e285da3af70f5c7a4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "base_model_id = \"mistralai/Mistral-7B-v0.1\"\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_id,  # Mistral, same as before\n",
    "    quantization_config=bnb_config,  # Same quantization config as before\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "eval_tokenizer = AutoTokenizer.from_pretrained(base_model_id, add_bos_token=True, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "lUMWQkXD4Z3N"
   },
   "outputs": [],
   "source": [
    "from peft import PeftModel\n",
    "\n",
    "ft_model = PeftModel.from_pretrained(base_model, \"output/checkpoint-500\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mwm1UxK68tdE",
    "outputId": "812b5fb1-5bee-4c50-bad1-058b55fd7164"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "eval_prompt = f\"### Ingredients: {df_ar['ingredients'].iloc[265]}\\n### Generate Title and Instructions:\\n### Title:\"\n",
    "\n",
    "model_input = eval_tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "ft_model.eval()\n",
    "with torch.no_grad():\n",
    "    generated_texts = eval_tokenizer.decode(ft_model.generate(**model_input, max_new_tokens=200, repetition_penalty=1.15)[0], skip_special_tokens=True)\n",
    "    print(generated_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "obaG_MZzuOvr"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/datasets/load.py:759: FutureWarning: The repository for bleu contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.1/metrics/bleu/bleu.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/datasets/load.py:759: FutureWarning: The repository for rouge contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.1/metrics/rouge/rouge.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/datasets/load.py:759: FutureWarning: The repository for meteor contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.1/metrics/meteor/meteor.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "[nltk_data] Downloading package wordnet to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install rouge_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def evaluate_and_plot(generated_text, reference_text):\n",
    "    from datasets import load_metric\n",
    "    bleu_metric = load_metric('bleu')\n",
    "    rouge_metric = load_metric('rouge')\n",
    "    meteor_metric = load_metric('meteor')\n",
    "\n",
    "    predictions = [generated_text.split()]\n",
    "    references = [[reference_text.split()]]\n",
    "\n",
    "    # Compute metrics\n",
    "    bleu_result = bleu_metric.compute(predictions=predictions, references=references)['bleu']\n",
    "    rouge_result = rouge_metric.compute(predictions=[generated_text], references=[reference_text])['rouge1'].mid.fmeasure\n",
    "    meteor_result = meteor_metric.compute(predictions=[generated_text], references=[reference_text])['meteor']\n",
    "\n",
    "    # Prepare data for plotting\n",
    "    metrics = ['BLEU', 'ROUGE-1', 'METEOR']\n",
    "    scores = [bleu_result, rouge_result, meteor_result]\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.bar(metrics, scores, color=['blue', 'green', 'red'])\n",
    "    plt.xlabel('Metrics')\n",
    "    plt.ylabel('Scores')\n",
    "    plt.title('Evaluation Metrics')\n",
    "    plt.ylim(0, 1)  # Assuming the scores are normalized between 0 and 1\n",
    "    plt.show()\n",
    "\n",
    "# Example generated and reference texts\n",
    "reference_texts = f\"### Ingredients: {df_ar['ingredients'].iloc[265]}\\n### Generate Title and Instructions:\\n### Title:{df_ar['title'].iloc[265]}\\n### Instructions: {df_ar['instructions'].iloc[265]}\"\n",
    "\n",
    "# Generate plot\n",
    "evaluate_and_plot(generated_texts, reference_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "include_colab_link": true,
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "23e56508698148a396955a35b8feb7da": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "HTMLStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "HTMLStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "StyleView",
      "background": null,
      "description_width": "",
      "font_size": null,
      "text_color": null
     }
    },
    "2d7614b2f7164f63bd78dc5de95ea1ff": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "2.0.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "2.0.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border_bottom": null,
      "border_left": null,
      "border_right": null,
      "border_top": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3c8da0d7d977480daec405cbd81ce475": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3fc14a395f1d4569865cbeea819c42c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "2.0.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_allow_html": false,
      "layout": "IPY_MODEL_f711cc2c2590496eb21e79a64e16660f",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_e3eb380a732c4ac4aa897968f546f1c8",
      "tabbable": null,
      "tooltip": null,
      "value": "â€‡2/2â€‡[00:56&lt;00:00,â€‡26.61s/it]"
     }
    },
    "58c64e0d7d764deb9a80ee6ab8a0be95": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "2.0.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "2.0.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border_bottom": null,
      "border_left": null,
      "border_right": null,
      "border_top": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5f2a769a466e4c8ebed1b5eb555390cb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "2.0.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "2.0.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border_bottom": null,
      "border_left": null,
      "border_right": null,
      "border_top": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6640c21d6b354e1fb37300e965bd062d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "2.0.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_allow_html": false,
      "layout": "IPY_MODEL_efdb470c4faf447e8fb73326da34a641",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8688af750cff4c9885fdf03c322b579b",
      "tabbable": null,
      "tooltip": null,
      "value": 2
     }
    },
    "6c7723b53aa749cf93987e4e5fa1da32": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "2.0.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_allow_html": false,
      "layout": "IPY_MODEL_9b238e7f08264805b524ac3100444476",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_7afe9062140a45099f85e96d07db9a27",
      "tabbable": null,
      "tooltip": null,
      "value": "Loadingâ€‡checkpointâ€‡shards:â€‡100%"
     }
    },
    "7afe9062140a45099f85e96d07db9a27": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "HTMLStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "HTMLStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "StyleView",
      "background": null,
      "description_width": "",
      "font_size": null,
      "text_color": null
     }
    },
    "80b02623217c4864a5802c1215d92f5a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "2.0.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "2.0.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border_bottom": null,
      "border_left": null,
      "border_right": null,
      "border_top": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8688af750cff4c9885fdf03c322b579b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "908522ef9bd94e6f8a02e4642ee38a0c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "2.0.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d8ce7a5f583f4fb7948614b68fd31404",
       "IPY_MODEL_6640c21d6b354e1fb37300e965bd062d",
       "IPY_MODEL_f24c5e848078403db2719e2c13c26f3d"
      ],
      "layout": "IPY_MODEL_58c64e0d7d764deb9a80ee6ab8a0be95",
      "tabbable": null,
      "tooltip": null
     }
    },
    "9b238e7f08264805b524ac3100444476": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "2.0.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "2.0.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border_bottom": null,
      "border_left": null,
      "border_right": null,
      "border_top": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a32c582e23e44efb86d9ab2203e7525f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "HTMLStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "HTMLStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "StyleView",
      "background": null,
      "description_width": "",
      "font_size": null,
      "text_color": null
     }
    },
    "ccc1bd2c0a454f96bd2fc895043dde0f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "2.0.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6c7723b53aa749cf93987e4e5fa1da32",
       "IPY_MODEL_ce0066c99ea64879b679fb68afe2e47d",
       "IPY_MODEL_3fc14a395f1d4569865cbeea819c42c6"
      ],
      "layout": "IPY_MODEL_5f2a769a466e4c8ebed1b5eb555390cb",
      "tabbable": null,
      "tooltip": null
     }
    },
    "ce0066c99ea64879b679fb68afe2e47d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "2.0.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_allow_html": false,
      "layout": "IPY_MODEL_ed6210d9752348ab9478e527c28c3c2b",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3c8da0d7d977480daec405cbd81ce475",
      "tabbable": null,
      "tooltip": null,
      "value": 2
     }
    },
    "d8ce7a5f583f4fb7948614b68fd31404": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "2.0.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_allow_html": false,
      "layout": "IPY_MODEL_80b02623217c4864a5802c1215d92f5a",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_a32c582e23e44efb86d9ab2203e7525f",
      "tabbable": null,
      "tooltip": null,
      "value": "Loadingâ€‡checkpointâ€‡shards:â€‡100%"
     }
    },
    "e3eb380a732c4ac4aa897968f546f1c8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "HTMLStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "HTMLStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "StyleView",
      "background": null,
      "description_width": "",
      "font_size": null,
      "text_color": null
     }
    },
    "ed6210d9752348ab9478e527c28c3c2b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "2.0.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "2.0.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border_bottom": null,
      "border_left": null,
      "border_right": null,
      "border_top": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "efdb470c4faf447e8fb73326da34a641": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "2.0.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "2.0.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border_bottom": null,
      "border_left": null,
      "border_right": null,
      "border_top": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f24c5e848078403db2719e2c13c26f3d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "2.0.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_allow_html": false,
      "layout": "IPY_MODEL_2d7614b2f7164f63bd78dc5de95ea1ff",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_23e56508698148a396955a35b8feb7da",
      "tabbable": null,
      "tooltip": null,
      "value": "â€‡2/2â€‡[00:08&lt;00:00,â€‡â€‡3.98s/it]"
     }
    },
    "f711cc2c2590496eb21e79a64e16660f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "2.0.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "2.0.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border_bottom": null,
      "border_left": null,
      "border_right": null,
      "border_top": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
