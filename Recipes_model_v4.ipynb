{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/MattRamb97/Erasmus_Hardgainers/blob/main/Recipes_model_v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QgSEjO0i7e_v"
   },
   "source": [
    "**RECIPES MODEL**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7EArwz7S8MEf"
   },
   "source": [
    "We utilized the URLs provided to access the datasets stored in the folder https://raw.githubusercontent.com/MattRamb97/Erasmus_Hardgainers/main/Datasets/\n",
    "\n",
    "using the pandas library. Subsequently, we identified an issue in the 'ingredients' column of the three datasets, characterized by the presence of the word 'ADVERTISEMENT', which we proceeded to remove. Additionally, we printed information regarding one of the datasets (the same information applies to the others) and their respective shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zORKNY3QbWaP",
    "outputId": "be36e788-d367-48e9-a1c0-1a35fe2336de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 39802 entries, rmK12Uau.ntP510KeImX506H6Mr6jTu to 2Q3Zpfgt/PUwn1YABjJ5A9T3ZW8xwVa\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   title         39522 non-null  object\n",
      " 1   ingredients   39522 non-null  object\n",
      " 2   instructions  39522 non-null  object\n",
      " 3   picture_link  39522 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 2.5+ MB\n",
      "\n",
      "From AR: (39522, 4)\n"
     ]
    }
   ],
   "source": [
    "url_1 = 'https://raw.githubusercontent.com/MattRamb97/Erasmus_Hardgainers/main/Datasets/recipes_raw_nosource_ar.json'\n",
    "\n",
    "import pandas as pd\n",
    "import sys\n",
    "df_ar = pd.read_json(url_1, orient='records', dtype='dict').transpose()\n",
    "df_ar.info()\n",
    "print()\n",
    "\n",
    "df_ar = df_ar.dropna(subset=['title', 'ingredients', 'instructions', 'picture_link'])\n",
    "\n",
    "df_ar['title'] = df_ar['title'].astype(str)\n",
    "\n",
    "df_ar['ingredients'] = df_ar['ingredients'].astype(str).str.replace('ADVERTISEMENT', '',regex=True)\n",
    "\n",
    "# Safely evaluate the 'ingredients' column\n",
    "def safe_eval(x):\n",
    "    try:\n",
    "        return ', '.join(eval(x))\n",
    "    except:\n",
    "        return ''  # Return an empty string in case of an error\n",
    "\n",
    "df_ar['ingredients'] = df_ar['ingredients'].apply(safe_eval)\n",
    "\n",
    "df_ar['instructions'] = df_ar['instructions'].astype(str)\n",
    "\n",
    "print('From AR:', df_ar.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s6mJc7q2TC5S"
   },
   "source": [
    "Cleaning of the ingredients from numbers, units of measure and ( , ) , /"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cZUHZoddMr1E",
    "outputId": "2098fc0d-2939-426f-e960-9ca9784dbd2f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport re\\n\\ndef clean_ingredients(ingredient):\\n    # Define the pattern to remove numbers, common units of measure, and unwanted characters including non-standard spaces\\n    pattern = r'\\x08\\\\d+\\\\.?\\\\d*|\\x08(?:oz|ounce|ounces|lb|pound|pounds|g|gram|grams|kg|kilogram|kilograms|ml|milliliter|milliliters|l|liter|liters|tbsp|tbs|tablespoon|tablespoons|tsp|teaspoon|teaspoons|cup|cups|pinch|pinches)\\x08|[()\\\\/]'\\n    # Replace the matched items with nothing (effectively removing them)\\n    cleaned_ingredient = re.sub(pattern, '', ingredient, flags=re.IGNORECASE)\\n    # Remove any kind of space-like characters and trim the string\\n    cleaned_ingredient = re.sub(r'\\\\s+', ' ', cleaned_ingredient).strip()\\n    # Remove any invisible characters or non-breaking spaces\\n    cleaned_ingredient = re.sub(r'[\\u200b-\\u200d\\ufeff]', '', cleaned_ingredient)\\n    return cleaned_ingredient\\n\\n# Apply the cleaning function to the ingredients column\\ndf_ar['ingredients'] = df_ar['ingredients'].apply(clean_ingredients)\\n\\nprint(df_ar['ingredients'].iloc[2])\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import re\n",
    "\n",
    "def clean_ingredients(ingredient):\n",
    "    # Define the pattern to remove numbers, common units of measure, and unwanted characters including non-standard spaces\n",
    "    pattern = r'\\b\\d+\\.?\\d*|\\b(?:oz|ounce|ounces|lb|pound|pounds|g|gram|grams|kg|kilogram|kilograms|ml|milliliter|milliliters|l|liter|liters|tbsp|tbs|tablespoon|tablespoons|tsp|teaspoon|teaspoons|cup|cups|pinch|pinches)\\b|[()\\/]'\n",
    "    # Replace the matched items with nothing (effectively removing them)\n",
    "    cleaned_ingredient = re.sub(pattern, '', ingredient, flags=re.IGNORECASE)\n",
    "    # Remove any kind of space-like characters and trim the string\n",
    "    cleaned_ingredient = re.sub(r'\\s+', ' ', cleaned_ingredient).strip()\n",
    "    # Remove any invisible characters or non-breaking spaces\n",
    "    cleaned_ingredient = re.sub(r'[\\u200B-\\u200D\\uFEFF]', '', cleaned_ingredient)\n",
    "    return cleaned_ingredient\n",
    "\n",
    "# Apply the cleaning function to the ingredients column\n",
    "df_ar['ingredients'] = df_ar['ingredients'].apply(clean_ingredients)\n",
    "\n",
    "print(df_ar['ingredients'].iloc[2])\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3GcEDJTI-KL4"
   },
   "source": [
    "We cleaned the three datasets using two function:\n",
    "- uncontract(): expands contracted words commonly found in English sentences into their full forms using regular expressions.\n",
    "- clean_recepies(): removes non-alphanumeric characters from the input text except for spaces and hyphens. It then replaces multiple spaces and hyphens with a single space and normalizes units of measurement (e.g., cups, tablespoons) by removing them. Next, it removes numerical digits, assuming they represent quantities. Finally, it normalizes whitespace by removing extra spaces and ensuring consistent spacing between words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fGLa2UZXF9g6",
    "outputId": "6521e95a-1fb4-4099-fb13-827cc35c4c3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (0.31.0.dev0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from accelerate) (1.26.4)\n",
      "Requirement already satisfied: torch>=1.10.0 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from accelerate) (2.3.0)\n",
      "Requirement already satisfied: pyyaml in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: huggingface-hub in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from accelerate) (0.23.0)\n",
      "Requirement already satisfied: psutil in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from accelerate) (5.9.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from accelerate) (24.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from accelerate) (0.4.3)\n",
      "Requirement already satisfied: triton==2.3.0 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2.3.0)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2.20.5)\n",
      "Requirement already satisfied: filelock in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.14.0)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: jinja2 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.11.0)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: sympy in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
      "Requirement already satisfied: networkx in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.3)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
      "Requirement already satisfied: fsspec in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2024.3.1)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: requests in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple/\n",
      "Requirement already satisfied: bitsandbytes in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (0.43.1)\n",
      "Requirement already satisfied: numpy in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from bitsandbytes) (1.26.4)\n",
      "Requirement already satisfied: torch in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from bitsandbytes) (2.3.0)\n",
      "Requirement already satisfied: jinja2 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch->bitsandbytes) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch->bitsandbytes) (8.9.2.26)\n",
      "Requirement already satisfied: sympy in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch->bitsandbytes) (1.12)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch->bitsandbytes) (10.3.2.106)\n",
      "Requirement already satisfied: networkx in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch->bitsandbytes) (3.3)\n",
      "Requirement already satisfied: filelock in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch->bitsandbytes) (3.14.0)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch->bitsandbytes) (2.20.5)\n",
      "Requirement already satisfied: triton==2.3.0 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch->bitsandbytes) (2.3.0)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch->bitsandbytes) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch->bitsandbytes) (4.11.0)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch->bitsandbytes) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: fsspec in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch->bitsandbytes) (2024.3.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from jinja2->torch->bitsandbytes) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from sympy->torch->bitsandbytes) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install accelerate\n",
    "!pip install -i https://pypi.org/simple/ bitsandbytes\n",
    "!pip install -q -U git+https://github.com/huggingface/transformers.git\n",
    "!pip install -q -U git+https://github.com/huggingface/peft.git\n",
    "!pip install -q -U git+https://github.com/huggingface/accelerate.git\n",
    "!pip install -q -U datasets scipy ipywidgets matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MhNc7-SuHIUc"
   },
   "source": [
    "Create a formatting_func to structure training examples as prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "iP0ZOpuRGbb8"
   },
   "outputs": [],
   "source": [
    "def formatting_func(ingredients, title, instructions):\n",
    "    text = f\"### Ingredients: {ingredients}\\n### Generate Title and Instructions:\\n### Title:{title}\\n### Instructions: {instructions}\"\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2dXRlDN-HM-U"
   },
   "source": [
    "Load Mistral - mistralai/Mistral-7B-v0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408,
     "referenced_widgets": [
      "908522ef9bd94e6f8a02e4642ee38a0c",
      "d8ce7a5f583f4fb7948614b68fd31404",
      "6640c21d6b354e1fb37300e965bd062d",
      "f24c5e848078403db2719e2c13c26f3d",
      "58c64e0d7d764deb9a80ee6ab8a0be95",
      "80b02623217c4864a5802c1215d92f5a",
      "a32c582e23e44efb86d9ab2203e7525f",
      "efdb470c4faf447e8fb73326da34a641",
      "8688af750cff4c9885fdf03c322b579b",
      "2d7614b2f7164f63bd78dc5de95ea1ff",
      "23e56508698148a396955a35b8feb7da"
     ]
    },
    "id": "I_MSkGl3UOiw",
    "outputId": "279d1f3d-0889-443c-a6f7-5742023404a9"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcfd57b04c524fa3b7c9cfb61e604d30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1649b7c89ed497c9d0bdbd9fbea1c76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "base_model_id = \"mistralai/Mistral-7B-v0.1\"\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(base_model_id, quantization_config=bnb_config, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uh_eFIQ4IEYS"
   },
   "source": [
    "Set up the tokenizer. Add padding on the left as it makes training use less memory. For model_max_length, it's helpful to get a distribution of your data lengths. Let's first tokenize without the truncation/padding, so we can get a length distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "SrALxLNtILcT"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    base_model_id,\n",
    "    padding_side=\"left\",\n",
    "    add_eos_token=True,\n",
    "    add_bos_token=True,\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "def generate_and_tokenize_prompt(ingredients, title, instructions):\n",
    "    return tokenizer(formatting_func(ingredients, title, instructions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6qxSioghIXcp"
   },
   "source": [
    "Reformat the prompt and tokenize each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Efy3OWxtIbNy"
   },
   "outputs": [],
   "source": [
    "tokenized_titles = []\n",
    "tokenized_ingredients = []\n",
    "tokenized_instructions = []\n",
    "\n",
    "for ingredients, title, instructions in zip(df_ar['ingredients'].iloc[:1000], df_ar['title'].iloc[:1000], df_ar['instructions'].iloc[:1000]):\n",
    "    tokenized_ingredients.append(generate_and_tokenize_prompt( ingredients,title,instructions))\n",
    "    tokenized_titles.append(generate_and_tokenize_prompt( ingredients,title, instructions))\n",
    "    tokenized_instructions.append(generate_and_tokenize_prompt( ingredients,title, instructions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_1v-yvq2KZDG"
   },
   "source": [
    "Let's get a distribution of our dataset lengths, so we can determine the appropriate max_length for our input tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 581
    },
    "id": "sc9oNJ75KZwZ",
    "outputId": "297bd40e-a400-47df-dcd4-9c652120ccd6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_data_lengths(tokenized_titles, tokenized_ingredients):\n",
    "    lengths = [len(x['input_ids']) for x in tokenized_titles]\n",
    "    lengths += [len(x['input_ids']) for x in tokenized_ingredients]\n",
    "    print(len(lengths))\n",
    "\n",
    "    # Plotting the histogram\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(lengths, bins=20, alpha=0.7, color='blue')\n",
    "    plt.xlabel('Length of input_ids')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Distribution of Lengths of input_ids')\n",
    "    plt.show()\n",
    "\n",
    "plot_data_lengths(tokenized_titles, tokenized_ingredients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ZbTte5073fEL"
   },
   "outputs": [],
   "source": [
    "max_length = 365  # This was an appropriate max length for my dataset\n",
    "\n",
    "def generate_and_tokenize_prompt2(ingredients, title, instructions):\n",
    "\n",
    "    ingredients_result = tokenizer(\n",
    "        ingredients,\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    title_result = tokenizer(\n",
    "        title,\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    instructions_result = tokenizer(\n",
    "        instructions,\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    ingredients_result[\"labels\"] = ingredients_result[\"input_ids\"].copy()\n",
    "    title_result[\"labels\"] = title_result[\"input_ids\"].copy()\n",
    "    instructions_result[\"labels\"] = title_result[\"input_ids\"].copy()\n",
    "\n",
    "    return ingredients_result, title_result, instructions_result\n",
    "\n",
    "# Tokenization of the dataset\n",
    "tokenized_data = []\n",
    "for ingredients, title, instructions in zip(df_ar['ingredients'].iloc[:1000], df_ar['title'].iloc[:1000], df_ar['instructions'].iloc[:1000]):\n",
    "    ingredients_result, title_result, instructions_result = generate_and_tokenize_prompt2(ingredients, title, instructions)\n",
    "    # Concatenating results into a single input\n",
    "    combined_input_ids = ingredients_result[\"input_ids\"] + title_result[\"input_ids\"] + instructions_result[\"input_ids\"]\n",
    "    combined_labels = ingredients_result[\"labels\"] + title_result[\"labels\"] +  instructions_result[\"labels\"]\n",
    "    tokenized_data.append({'input_ids': combined_input_ids, 'labels': combined_labels})\n",
    "\n",
    "# Split data into training and evaluation datasets\n",
    "split_index = int(0.8 * len(tokenized_data))\n",
    "train_dataset = tokenized_data[:split_index]\n",
    "eval_dataset = tokenized_data[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fke7hj1JPyQT",
    "outputId": "5e5ca835-3aa1-4af6-9950-e7481f0c856b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Ingredients: 1/4 cup all-purpose flour for coating , 1/2 teaspoon salt , 1/4 teaspoon ground black pepper , 1/2 teaspoon dried oregano , 4 skinless, boneless chicken breast halves - pounded 1/4 inch thick , 4 tablespoons butter , 4 tablespoons olive oil , 1 cup sliced mushrooms , 1/2 cup Marsala wine , 1/4 cup cooking sherry , \n",
      "### Generate Title and Instructions:\n",
      "### Title: Chicken Marsala\n",
      "### Instructions:\n",
      "In a shallow bowl or pie plate, mix together the flour, salt, pepper, and oregano. Coat the chicken with the mixture; set aside. In a large skillet over medium heat, melt the butter with the olive oil. Add the chicken breasts to the pan and cook until brown on both sides and cooked through, about 5 minutes per side. Remove from the pan and keep warm. Pour off any excess fat in the pan. Saute the mushrooms in the same pan until tender, about 3 minutes. Return the chicken to the pan along with any juices that have accumulated. Stir in the Marsala and sherry. Simmer until the sauce has reduced by half, about 5 minutes.\n"
     ]
    }
   ],
   "source": [
    "eval_prompt = f\"### Ingredients: {df_ar['ingredients'].iloc[57]}\\n### Generate Title and Instructions:\\n### Title:\"\n",
    "\n",
    "# Init an eval tokenizer that doesn't add padding or eos token\n",
    "eval_tokenizer = AutoTokenizer.from_pretrained(\n",
    "    base_model_id,\n",
    "    add_bos_token=True,\n",
    ")\n",
    "\n",
    "model_input = eval_tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    print(eval_tokenizer.decode(model.generate(**model_input, max_new_tokens=256, repetition_penalty=1.15)[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k4qY_S0EaOPs"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JMDv9mCeV-il"
   },
   "source": [
    "**Set Up LoRA**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "txXs94_zWCcQ"
   },
   "source": [
    "Now, to start our fine-tuning, we have to apply some preprocessing to the model to prepare it for training. For that use the prepare_model_for_kbit_training method from PEFT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "k-rUo6KTWFMU"
   },
   "outputs": [],
   "source": [
    "from peft import prepare_model_for_kbit_training\n",
    "\n",
    "model.gradient_checkpointing_enable()\n",
    "model = prepare_model_for_kbit_training(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "JTws6uDbWIOD"
   },
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YMHP0xk-WNVV"
   },
   "source": [
    "Let's print the model to examine its layers, as we will apply QLoRA to all the linear layers of the model. Those layers are q_proj, k_proj, v_proj, o_proj, gate_proj, up_proj, down_proj, and lm_head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z-6Iqd0KYCID",
    "outputId": "a0569bd1-2358-4f92-c5f8-336286a831be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MistralForCausalLM(\n",
      "  (model): MistralModel(\n",
      "    (embed_tokens): Embedding(32000, 4096)\n",
      "    (layers): ModuleList(\n",
      "      (0-31): 32 x MistralDecoderLayer(\n",
      "        (self_attn): MistralSdpaAttention(\n",
      "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): MistralRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): MistralMLP(\n",
      "          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): MistralRMSNorm()\n",
      "        (post_attention_layernorm): MistralRMSNorm()\n",
      "      )\n",
      "    )\n",
      "    (norm): MistralRMSNorm()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d13VfHnQYHw5"
   },
   "source": [
    "Here we define the LoRA config.\n",
    "\n",
    "r is the rank of the low-rank matrix used in the adapters, which thus controls the number of parameters trained. A higher rank will allow for more expressivity, but there is a compute tradeoff.\n",
    "\n",
    "alpha is the scaling factor for the learned weights. The weight matrix is scaled by alpha/r, and thus a higher value for alpha assigns more weight to the LoRA activations.\n",
    "\n",
    "The values used in the QLoRA paper were r=64 and lora_alpha=16, and these are said to generalize well, but we will use r=32 and lora_alpha=64 so that we have more emphasis on the new fine-tuned data while also reducing computational complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yvugWrLvYPZU",
    "outputId": "ac8a27cb-5ca3-4d55-ba69-7a1418a6f90a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 85041152 || all params: 3837112320 || trainable%: 2.2162799758751914\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "config = LoraConfig(\n",
    "    r=32,\n",
    "    lora_alpha=64,\n",
    "    target_modules=[\n",
    "        \"q_proj\",\n",
    "        \"k_proj\",\n",
    "        \"v_proj\",\n",
    "        \"o_proj\",\n",
    "        \"gate_proj\",\n",
    "        \"up_proj\",\n",
    "        \"down_proj\",\n",
    "        \"lm_head\",\n",
    "    ],\n",
    "    bias=\"none\",\n",
    "    lora_dropout=0.05,  # Conventional\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, config)\n",
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4xhf8d0LYUdD"
   },
   "source": [
    "See how the model looks different now, with the LoRA adapters added:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v6y9Rys9YWey",
    "outputId": "95594d1f-6562-4cb6-a152-8da3f24cf272"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeftModelForCausalLM(\n",
      "  (base_model): LoraModel(\n",
      "    (model): MistralForCausalLM(\n",
      "      (model): MistralModel(\n",
      "        (embed_tokens): Embedding(32000, 4096)\n",
      "        (layers): ModuleList(\n",
      "          (0-31): 32 x MistralDecoderLayer(\n",
      "            (self_attn): MistralSdpaAttention(\n",
      "              (q_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (k_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=1024, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (v_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=1024, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (o_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (rotary_emb): MistralRotaryEmbedding()\n",
      "            )\n",
      "            (mlp): MistralMLP(\n",
      "              (gate_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=14336, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (up_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=14336, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (down_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=14336, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (act_fn): SiLU()\n",
      "            )\n",
      "            (input_layernorm): MistralRMSNorm()\n",
      "            (post_attention_layernorm): MistralRMSNorm()\n",
      "          )\n",
      "        )\n",
      "        (norm): MistralRMSNorm()\n",
      "      )\n",
      "      (lm_head): lora.Linear(\n",
      "        (base_layer): Linear(in_features=4096, out_features=32000, bias=False)\n",
      "        (lora_dropout): ModuleDict(\n",
      "          (default): Dropout(p=0.05, inplace=False)\n",
      "        )\n",
      "        (lora_A): ModuleDict(\n",
      "          (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "        )\n",
      "        (lora_B): ModuleDict(\n",
      "          (default): Linear(in_features=32, out_features=32000, bias=False)\n",
      "        )\n",
      "        (lora_embedding_A): ParameterDict()\n",
      "        (lora_embedding_B): ParameterDict()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tIu5yNhYaRmq"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nkBAVmb3ZZ6e"
   },
   "source": [
    "**TRAINING LoRA MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "PGTxRTgLZi_0"
   },
   "outputs": [],
   "source": [
    "if torch.cuda.device_count() > 1: # If more than 1 GPU\n",
    "    model.is_parallelizable = True\n",
    "    model.model_parallel = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "J4Nh-UgTZktM"
   },
   "outputs": [],
   "source": [
    "from accelerate import FullyShardedDataParallelPlugin, Accelerator\n",
    "from torch.distributed.fsdp.fully_sharded_data_parallel import FullOptimStateDictConfig, FullStateDictConfig\n",
    "\n",
    "fsdp_plugin = FullyShardedDataParallelPlugin(\n",
    "    state_dict_config=FullStateDictConfig(offload_to_cpu=True, rank0_only=False),\n",
    "    optim_state_dict_config=FullOptimStateDictConfig(offload_to_cpu=True, rank0_only=False),\n",
    ")\n",
    "\n",
    "accelerator = Accelerator(fsdp_plugin=fsdp_plugin)\n",
    "\n",
    "model = accelerator.prepare_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_QY-O7nOa3AZ",
    "outputId": "f4ace141-0cdd-431c-dabf-b9a490e52185"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmatteo-rambaldi\u001b[0m (\u001b[33mrecipes_model\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "!pip install -q wandb -U\n",
    "\n",
    "import wandb, os\n",
    "wandb.login()\n",
    "\n",
    "wandb_project = \"journal-finetune\"\n",
    "if len(wandb_project) > 0:\n",
    "    os.environ[\"WANDB_PROJECT\"] = wandb_project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 974
    },
    "id": "BeEHSdGmZyjQ",
    "outputId": "12c8bf03-2316-4a2a-c40d-96655b66fe2d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/transformers/training_args.py:1463: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/verb-workspace/wandb/run-20240506_103201-01333x2r</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/recipes_model/journal-finetune/runs/01333x2r' target=\"_blank\">mistral-recepies-model_v3-2024-05-06-10-32</a></strong> to <a href='https://wandb.ai/recipes_model/journal-finetune' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/recipes_model/journal-finetune' target=\"_blank\">https://wandb.ai/recipes_model/journal-finetune</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/recipes_model/journal-finetune/runs/01333x2r' target=\"_blank\">https://wandb.ai/recipes_model/journal-finetune/runs/01333x2r</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 28:00, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>2.618300</td>\n",
       "      <td>0.853080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.743100</td>\n",
       "      <td>0.797921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.700400</td>\n",
       "      <td>0.788783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.708000</td>\n",
       "      <td>0.773781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.715500</td>\n",
       "      <td>0.772423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.735800</td>\n",
       "      <td>0.767999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.720600</td>\n",
       "      <td>0.764465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.687600</td>\n",
       "      <td>0.763219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.755691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.667200</td>\n",
       "      <td>0.753704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.728600</td>\n",
       "      <td>0.752415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.753619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.713800</td>\n",
       "      <td>0.748204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.680600</td>\n",
       "      <td>0.747401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.655000</td>\n",
       "      <td>0.745420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.731500</td>\n",
       "      <td>0.744347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.572900</td>\n",
       "      <td>0.751676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.516100</td>\n",
       "      <td>0.754586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.597500</td>\n",
       "      <td>0.753450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.597300</td>\n",
       "      <td>0.752288</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=500, training_loss=0.7737369346618652, metrics={'train_runtime': 1686.2882, 'train_samples_per_second': 0.593, 'train_steps_per_second': 0.297, 'total_flos': 4.727575719936e+16, 'train_loss': 0.7737369346618652, 'epoch': 1.25})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from datetime import datetime\n",
    "import torch\n",
    "\n",
    "project = \"recepies-model_v3\"\n",
    "base_model_name = \"mistral\"\n",
    "run_name = base_model_name + \"-\" + project\n",
    "output_dir = \"./\" + run_name\n",
    "\n",
    "# Initialize Trainer with your model and tokenizer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=TrainingArguments(\n",
    "        output_dir='./output',\n",
    "        warmup_steps=1,\n",
    "        per_device_train_batch_size=2,\n",
    "        gradient_accumulation_steps=1,\n",
    "        gradient_checkpointing=True,\n",
    "        max_steps=500,\n",
    "        learning_rate=2.5e-5,\n",
    "        fp16=True,\n",
    "        optim=\"paged_adamw_8bit\",\n",
    "        logging_steps=25,\n",
    "        logging_dir=\"./logs\",\n",
    "        save_strategy=\"steps\",\n",
    "        save_steps=25,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        eval_steps=25,\n",
    "        do_eval=True,\n",
    "        report_to=\"wandb\",\n",
    "        run_name=f\"{run_name}-{datetime.now().strftime('%Y-%m-%d-%H-%M')}\"\n",
    "    ),\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
    ")\n",
    "model.config.use_cache = False\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17,
     "referenced_widgets": [
      "ccc1bd2c0a454f96bd2fc895043dde0f",
      "6c7723b53aa749cf93987e4e5fa1da32",
      "ce0066c99ea64879b679fb68afe2e47d",
      "3fc14a395f1d4569865cbeea819c42c6",
      "5f2a769a466e4c8ebed1b5eb555390cb",
      "9b238e7f08264805b524ac3100444476",
      "7afe9062140a45099f85e96d07db9a27",
      "ed6210d9752348ab9478e527c28c3c2b",
      "3c8da0d7d977480daec405cbd81ce475",
      "f711cc2c2590496eb21e79a64e16660f",
      "e3eb380a732c4ac4aa897968f546f1c8"
     ]
    },
    "id": "2pHEKwMW4Y9K",
    "outputId": "3cdba9a4-bb89-4043-b33b-f99d7aeadcaf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0ab4d52eb5640e7be0edd8783ae30ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "base_model_id = \"mistralai/Mistral-7B-v0.1\"\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_id,  # Mistral, same as before\n",
    "    quantization_config=bnb_config,  # Same quantization config as before\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "eval_tokenizer = AutoTokenizer.from_pretrained(base_model_id, add_bos_token=True, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "lUMWQkXD4Z3N"
   },
   "outputs": [],
   "source": [
    "from peft import PeftModel\n",
    "\n",
    "ft_model = PeftModel.from_pretrained(base_model, \"output/checkpoint-450\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mwm1UxK68tdE",
    "outputId": "812b5fb1-5bee-4c50-bad1-058b55fd7164"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Ingredients: 1/4 cup all-purpose flour for coating , 1/2 teaspoon salt , 1/4 teaspoon ground black pepper , 1/2 teaspoon dried oregano , 4 skinless, boneless chicken breast halves - pounded 1/4 inch thick , 4 tablespoons butter , 4 tablespoons olive oil , 1 cup sliced mushrooms , 1/2 cup Marsala wine , 1/4 cup cooking sherry , \n",
      "### Generate Title and Instructions:\n",
      "### Title: Chicken Marsala\n",
      "### Instructions:\n",
      "In a shallow bowl or dish, mix together the flour, salt, pepper and oregano. Coat chicken pieces in mixture.\n",
      "Melt butter with olive oil in a large skillet over medium heat. Place chicken in pan, and brown on both sides. Remove from pan, and set aside.\n",
      "Add mushrooms to pan, and saute until tender. Return chicken to pan, and add Marsala wine and sherry. Cover, and simmer 10 minutes, turning once, until chicken is no longer pink and juices run clear.\n",
      "Serve with pasta if desired.\n",
      "### Nutrition Facts:\n",
      "Per Serving: 379 calories; protein 28g; carbohydrates 6.5g; fat 23.7g; cholesterol 96mg; sodium 498mg.\n"
     ]
    }
   ],
   "source": [
    "eval_prompt = f\"### Ingredients: {df_ar['ingredients'].iloc[57]}\\n### Generate Title and Instructions:\\n### Title:\"\n",
    "\n",
    "#f\"### Ingredients: {df_ar['ingredients'].iloc[1]}\\n### Generate Title and Instructions:\\n### Title:\"\n",
    "\n",
    "model_input = eval_tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "ft_model.eval()\n",
    "with torch.no_grad():\n",
    "    generated_texts = eval_tokenizer.decode(ft_model.generate(**model_input, max_new_tokens=200, repetition_penalty=1.15)[0], skip_special_tokens=True)\n",
    "    print(generated_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "obaG_MZzuOvr"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rouge_score in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (0.1.2)\n",
      "Requirement already satisfied: six>=1.14.0 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from rouge_score) (1.16.0)\n",
      "Requirement already satisfied: absl-py in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from rouge_score) (2.1.0)\n",
      "Requirement already satisfied: numpy in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from rouge_score) (1.26.4)\n",
      "Requirement already satisfied: nltk in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from rouge_score) (3.8.1)\n",
      "Requirement already satisfied: joblib in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from nltk->rouge_score) (1.4.2)\n",
      "Requirement already satisfied: click in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from nltk->rouge_score) (8.1.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from nltk->rouge_score) (2024.4.28)\n",
      "Requirement already satisfied: tqdm in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from nltk->rouge_score) (4.66.4)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/datasets/load.py:759: FutureWarning: The repository for bleu contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.1/metrics/bleu/bleu.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/datasets/load.py:759: FutureWarning: The repository for rouge contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.1/metrics/rouge/rouge.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/datasets/load.py:759: FutureWarning: The repository for meteor contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.1/metrics/meteor/meteor.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "[nltk_data] Downloading package wordnet to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install rouge_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def evaluate_and_plot(generated_text, reference_text):\n",
    "    from datasets import load_metric\n",
    "    bleu_metric = load_metric('bleu')\n",
    "    rouge_metric = load_metric('rouge')\n",
    "    meteor_metric = load_metric('meteor')\n",
    "\n",
    "    predictions = [generated_text.split()]\n",
    "    references = [[reference_text.split()]]\n",
    "\n",
    "    # Compute metrics\n",
    "    bleu_result = bleu_metric.compute(predictions=predictions, references=references)['bleu']\n",
    "    rouge_result = rouge_metric.compute(predictions=[generated_text], references=[reference_text])['rouge1'].mid.fmeasure\n",
    "    meteor_result = meteor_metric.compute(predictions=[generated_text], references=[reference_text])['meteor']\n",
    "\n",
    "    # Prepare data for plotting\n",
    "    metrics = ['BLEU', 'ROUGE-1', 'METEOR']\n",
    "    scores = [bleu_result, rouge_result, meteor_result]\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.bar(metrics, scores, color=['blue', 'green', 'red'])\n",
    "    plt.xlabel('Metrics')\n",
    "    plt.ylabel('Scores')\n",
    "    plt.title('Evaluation Metrics')\n",
    "    plt.ylim(0, 1)  # Assuming the scores are normalized between 0 and 1\n",
    "    plt.show()\n",
    "\n",
    "# Example generated and reference texts\n",
    "reference_texts = f\"### Ingredients: {df_ar['ingredients'].iloc[57]}\\n### Generate Title and Instructions:\\n### Title:{df_ar['title'].iloc[57]}\\n### Instructions: {df_ar['instructions'].iloc[57]}\"\n",
    "\n",
    "# Generate plot\n",
    "evaluate_and_plot(generated_texts, reference_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "include_colab_link": true,
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "23e56508698148a396955a35b8feb7da": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "HTMLStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "HTMLStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "StyleView",
      "background": null,
      "description_width": "",
      "font_size": null,
      "text_color": null
     }
    },
    "2d7614b2f7164f63bd78dc5de95ea1ff": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "2.0.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "2.0.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border_bottom": null,
      "border_left": null,
      "border_right": null,
      "border_top": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3c8da0d7d977480daec405cbd81ce475": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3fc14a395f1d4569865cbeea819c42c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "2.0.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_allow_html": false,
      "layout": "IPY_MODEL_f711cc2c2590496eb21e79a64e16660f",
      "placeholder": "​",
      "style": "IPY_MODEL_e3eb380a732c4ac4aa897968f546f1c8",
      "tabbable": null,
      "tooltip": null,
      "value": " 2/2 [00:56&lt;00:00, 26.61s/it]"
     }
    },
    "58c64e0d7d764deb9a80ee6ab8a0be95": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "2.0.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "2.0.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border_bottom": null,
      "border_left": null,
      "border_right": null,
      "border_top": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5f2a769a466e4c8ebed1b5eb555390cb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "2.0.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "2.0.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border_bottom": null,
      "border_left": null,
      "border_right": null,
      "border_top": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6640c21d6b354e1fb37300e965bd062d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "2.0.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_allow_html": false,
      "layout": "IPY_MODEL_efdb470c4faf447e8fb73326da34a641",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8688af750cff4c9885fdf03c322b579b",
      "tabbable": null,
      "tooltip": null,
      "value": 2
     }
    },
    "6c7723b53aa749cf93987e4e5fa1da32": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "2.0.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_allow_html": false,
      "layout": "IPY_MODEL_9b238e7f08264805b524ac3100444476",
      "placeholder": "​",
      "style": "IPY_MODEL_7afe9062140a45099f85e96d07db9a27",
      "tabbable": null,
      "tooltip": null,
      "value": "Loading checkpoint shards: 100%"
     }
    },
    "7afe9062140a45099f85e96d07db9a27": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "HTMLStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "HTMLStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "StyleView",
      "background": null,
      "description_width": "",
      "font_size": null,
      "text_color": null
     }
    },
    "80b02623217c4864a5802c1215d92f5a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "2.0.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "2.0.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border_bottom": null,
      "border_left": null,
      "border_right": null,
      "border_top": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8688af750cff4c9885fdf03c322b579b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "908522ef9bd94e6f8a02e4642ee38a0c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "2.0.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d8ce7a5f583f4fb7948614b68fd31404",
       "IPY_MODEL_6640c21d6b354e1fb37300e965bd062d",
       "IPY_MODEL_f24c5e848078403db2719e2c13c26f3d"
      ],
      "layout": "IPY_MODEL_58c64e0d7d764deb9a80ee6ab8a0be95",
      "tabbable": null,
      "tooltip": null
     }
    },
    "9b238e7f08264805b524ac3100444476": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "2.0.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "2.0.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border_bottom": null,
      "border_left": null,
      "border_right": null,
      "border_top": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a32c582e23e44efb86d9ab2203e7525f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "HTMLStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "HTMLStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "StyleView",
      "background": null,
      "description_width": "",
      "font_size": null,
      "text_color": null
     }
    },
    "ccc1bd2c0a454f96bd2fc895043dde0f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "2.0.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6c7723b53aa749cf93987e4e5fa1da32",
       "IPY_MODEL_ce0066c99ea64879b679fb68afe2e47d",
       "IPY_MODEL_3fc14a395f1d4569865cbeea819c42c6"
      ],
      "layout": "IPY_MODEL_5f2a769a466e4c8ebed1b5eb555390cb",
      "tabbable": null,
      "tooltip": null
     }
    },
    "ce0066c99ea64879b679fb68afe2e47d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "2.0.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_allow_html": false,
      "layout": "IPY_MODEL_ed6210d9752348ab9478e527c28c3c2b",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3c8da0d7d977480daec405cbd81ce475",
      "tabbable": null,
      "tooltip": null,
      "value": 2
     }
    },
    "d8ce7a5f583f4fb7948614b68fd31404": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "2.0.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_allow_html": false,
      "layout": "IPY_MODEL_80b02623217c4864a5802c1215d92f5a",
      "placeholder": "​",
      "style": "IPY_MODEL_a32c582e23e44efb86d9ab2203e7525f",
      "tabbable": null,
      "tooltip": null,
      "value": "Loading checkpoint shards: 100%"
     }
    },
    "e3eb380a732c4ac4aa897968f546f1c8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "HTMLStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "HTMLStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "StyleView",
      "background": null,
      "description_width": "",
      "font_size": null,
      "text_color": null
     }
    },
    "ed6210d9752348ab9478e527c28c3c2b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "2.0.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "2.0.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border_bottom": null,
      "border_left": null,
      "border_right": null,
      "border_top": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "efdb470c4faf447e8fb73326da34a641": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "2.0.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "2.0.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border_bottom": null,
      "border_left": null,
      "border_right": null,
      "border_top": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f24c5e848078403db2719e2c13c26f3d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "2.0.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_allow_html": false,
      "layout": "IPY_MODEL_2d7614b2f7164f63bd78dc5de95ea1ff",
      "placeholder": "​",
      "style": "IPY_MODEL_23e56508698148a396955a35b8feb7da",
      "tabbable": null,
      "tooltip": null,
      "value": " 2/2 [00:08&lt;00:00,  3.98s/it]"
     }
    },
    "f711cc2c2590496eb21e79a64e16660f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "2.0.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "2.0.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border_bottom": null,
      "border_left": null,
      "border_right": null,
      "border_top": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
