{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/MattRamb97/Erasmus_Hardgainers/blob/main/Recipes_model_v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QgSEjO0i7e_v"
   },
   "source": [
    "**RECIPES MODEL**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7EArwz7S8MEf"
   },
   "source": [
    "We utilized the URLs provided to access the datasets stored in the folder https://raw.githubusercontent.com/MattRamb97/Erasmus_Hardgainers/main/Datasets/\n",
    "\n",
    "using the pandas library. Subsequently, we identified an issue in the 'ingredients' column of the three datasets, characterized by the presence of the word 'ADVERTISEMENT', which we proceeded to remove. Additionally, we printed information regarding one of the datasets (the same information applies to the others) and their respective shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zORKNY3QbWaP",
    "outputId": "be36e788-d367-48e9-a1c0-1a35fe2336de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (2.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: six>=1.5 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 39802 entries, rmK12Uau.ntP510KeImX506H6Mr6jTu to 2Q3Zpfgt/PUwn1YABjJ5A9T3ZW8xwVa\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   title         39522 non-null  object\n",
      " 1   ingredients   39522 non-null  object\n",
      " 2   instructions  39522 non-null  object\n",
      " 3   picture_link  39522 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 2.5+ MB\n",
      "\n",
      "From AR: (39522, 4)\n"
     ]
    }
   ],
   "source": [
    "url_1 = 'https://raw.githubusercontent.com/MattRamb97/Erasmus_Hardgainers/main/Datasets/recipes_raw_nosource_ar.json'\n",
    "\n",
    "!pip install pandas\n",
    "import pandas as pd\n",
    "import sys\n",
    "df_ar = pd.read_json(url_1, orient='records', dtype='dict').transpose()\n",
    "df_ar.info()\n",
    "print()\n",
    "\n",
    "df_ar = df_ar.dropna(subset=['title', 'ingredients', 'instructions', 'picture_link'])\n",
    "\n",
    "df_ar['title'] = df_ar['title'].astype(str)\n",
    "\n",
    "df_ar['ingredients'] = df_ar['ingredients'].astype(str).str.replace('ADVERTISEMENT', '',regex=True)\n",
    "\n",
    "# Safely evaluate the 'ingredients' column\n",
    "def safe_eval(x):\n",
    "    try:\n",
    "        return ', '.join(eval(x))\n",
    "    except:\n",
    "        return ''  # Return an empty string in case of an error\n",
    "\n",
    "df_ar['ingredients'] = df_ar['ingredients'].apply(safe_eval)\n",
    "\n",
    "df_ar['instructions'] = df_ar['instructions'].astype(str)\n",
    "\n",
    "print('From AR:', df_ar.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s6mJc7q2TC5S"
   },
   "source": [
    "Cleaning of the ingredients from numbers, units of measure and ( , ) , /"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cZUHZoddMr1E",
    "outputId": "2098fc0d-2939-426f-e960-9ca9784dbd2f"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_ingredients(ingredient):\n",
    "    # Define the pattern to remove numbers, common units of measure, and unwanted characters including non-standard spaces\n",
    "    pattern = r'\\b\\d+\\.?\\d*|\\b(?:oz|ounce|ounces|lb|pound|pounds|g|gram|grams|kg|kilogram|kilograms|ml|milliliter|milliliters|l|liter|liters|tbsp|tbs|tablespoon|tablespoons|tsp|teaspoon|teaspoons|cup|cups|pinch|pinches)\\b|[()\\/]'\n",
    "    # Replace the matched items with nothing (effectively removing them)\n",
    "    cleaned_ingredient = re.sub(pattern, '', ingredient, flags=re.IGNORECASE)\n",
    "    # Remove any kind of space-like characters and trim the string\n",
    "    cleaned_ingredient = re.sub(r'\\s+', ' ', cleaned_ingredient).strip()\n",
    "    # Remove any invisible characters or non-breaking spaces\n",
    "    cleaned_ingredient = re.sub(r'[\\u200B-\\u200D\\uFEFF]', '', cleaned_ingredient)\n",
    "    return cleaned_ingredient\n",
    "\n",
    "# Apply the cleaning function to the ingredients column\n",
    "df_ar['ingredients'] = df_ar['ingredients'].apply(clean_ingredients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3GcEDJTI-KL4"
   },
   "source": [
    "We cleaned the three datasets using two function:\n",
    "- uncontract(): expands contracted words commonly found in English sentences into their full forms using regular expressions.\n",
    "- clean_recepies(): removes non-alphanumeric characters from the input text except for spaces and hyphens. It then replaces multiple spaces and hyphens with a single space and normalizes units of measurement (e.g., cups, tablespoons) by removing them. Next, it removes numerical digits, assuming they represent quantities. Finally, it normalizes whitespace by removing extra spaces and ensuring consistent spacing between words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fGLa2UZXF9g6",
    "outputId": "6521e95a-1fb4-4099-fb13-827cc35c4c3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (0.31.0.dev0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from accelerate) (0.4.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from accelerate) (1.26.4)\n",
      "Requirement already satisfied: torch>=1.10.0 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from accelerate) (2.3.0)\n",
      "Requirement already satisfied: psutil in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from accelerate) (5.9.8)\n",
      "Requirement already satisfied: huggingface-hub in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from accelerate) (0.23.0)\n",
      "Requirement already satisfied: pyyaml in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from accelerate) (24.0)\n",
      "Requirement already satisfied: networkx in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
      "Requirement already satisfied: filelock in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.14.0)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.11.0)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2.20.5)\n",
      "Requirement already satisfied: triton==2.3.0 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
      "Requirement already satisfied: fsspec in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2024.3.1)\n",
      "Requirement already satisfied: jinja2 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
      "Requirement already satisfied: sympy in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.4)\n",
      "Requirement already satisfied: requests in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2.2.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple/\n",
      "Requirement already satisfied: bitsandbytes in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (0.43.1)\n",
      "Requirement already satisfied: torch in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from bitsandbytes) (2.3.0)\n",
      "Requirement already satisfied: numpy in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from bitsandbytes) (1.26.4)\n",
      "Requirement already satisfied: fsspec in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch->bitsandbytes) (2024.3.1)\n",
      "Requirement already satisfied: jinja2 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch->bitsandbytes) (3.1.3)\n",
      "Requirement already satisfied: sympy in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch->bitsandbytes) (1.12)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch->bitsandbytes) (2.20.5)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch->bitsandbytes) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: networkx in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch->bitsandbytes) (3.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch->bitsandbytes) (4.11.0)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch->bitsandbytes) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch->bitsandbytes) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch->bitsandbytes) (10.3.2.106)\n",
      "Requirement already satisfied: filelock in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch->bitsandbytes) (3.14.0)\n",
      "Requirement already satisfied: triton==2.3.0 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch->bitsandbytes) (2.3.0)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from jinja2->torch->bitsandbytes) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from sympy->torch->bitsandbytes) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install accelerate\n",
    "!pip install -i https://pypi.org/simple/ bitsandbytes\n",
    "!pip install -q -U git+https://github.com/huggingface/transformers.git\n",
    "!pip install -q -U git+https://github.com/huggingface/peft.git\n",
    "!pip install -q -U git+https://github.com/huggingface/accelerate.git\n",
    "!pip install -q -U datasets scipy ipywidgets matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MhNc7-SuHIUc"
   },
   "source": [
    "Create a formatting_func to structure training examples as prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "iP0ZOpuRGbb8"
   },
   "outputs": [],
   "source": [
    "def formatting_func(ingredients, title, instructions):\n",
    "    text = f\"### Ingredients: {ingredients}\\n### Generate Title and Instructions:\\n### Title:{title}\\n### Instructions: {instructions}\"\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2dXRlDN-HM-U"
   },
   "source": [
    "Load Mistral - mistralai/Mistral-7B-v0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408,
     "referenced_widgets": [
      "908522ef9bd94e6f8a02e4642ee38a0c",
      "d8ce7a5f583f4fb7948614b68fd31404",
      "6640c21d6b354e1fb37300e965bd062d",
      "f24c5e848078403db2719e2c13c26f3d",
      "58c64e0d7d764deb9a80ee6ab8a0be95",
      "80b02623217c4864a5802c1215d92f5a",
      "a32c582e23e44efb86d9ab2203e7525f",
      "efdb470c4faf447e8fb73326da34a641",
      "8688af750cff4c9885fdf03c322b579b",
      "2d7614b2f7164f63bd78dc5de95ea1ff",
      "23e56508698148a396955a35b8feb7da"
     ]
    },
    "id": "I_MSkGl3UOiw",
    "outputId": "279d1f3d-0889-443c-a6f7-5742023404a9"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a4a2568784142e5bf21325cc442510d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c1ae8d1ff6f4ebea8b8b86e4853effb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "MistralForCausalLM(\n",
       "  (model): MistralModel(\n",
       "    (embed_tokens): Embedding(32000, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x MistralDecoderLayer(\n",
       "        (self_attn): MistralSdpaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): MistralRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MistralMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): MistralRMSNorm()\n",
       "        (post_attention_layernorm): MistralRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): MistralRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "base_model_id = \"mistralai/Mistral-7B-v0.1\"\n",
    "\n",
    "# Load the model using the NVIDIA H100 GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = AutoModelForCausalLM.from_pretrained(base_model_id)\n",
    "model.to(device)  # Move model to GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uh_eFIQ4IEYS"
   },
   "source": [
    "Set up the tokenizer. Add padding on the left as it makes training use less memory. For model_max_length, it's helpful to get a distribution of your data lengths. Let's first tokenize without the truncation/padding, so we can get a length distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "SrALxLNtILcT"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    base_model_id,\n",
    "    padding_side=\"left\",\n",
    "    add_eos_token=True,\n",
    "    add_bos_token=True,\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "def generate_and_tokenize_prompt(ingredients, title, instructions):\n",
    "    return tokenizer(formatting_func(ingredients, title, instructions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6qxSioghIXcp"
   },
   "source": [
    "Reformat the prompt and tokenize each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Efy3OWxtIbNy"
   },
   "outputs": [],
   "source": [
    "tokenized_titles = []\n",
    "tokenized_ingredients = []\n",
    "tokenized_instructions = []\n",
    "\n",
    "for ingredients, title, instructions in zip(df_ar['ingredients'].iloc[:5000], df_ar['title'].iloc[:5000], df_ar['instructions'].iloc[:5000]):\n",
    "    tokenized_ingredients.append(generate_and_tokenize_prompt( ingredients,title,instructions))\n",
    "    tokenized_titles.append(generate_and_tokenize_prompt( ingredients,title, instructions))\n",
    "    tokenized_instructions.append(generate_and_tokenize_prompt( ingredients,title, instructions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_1v-yvq2KZDG"
   },
   "source": [
    "Let's get a distribution of our dataset lengths, so we can determine the appropriate max_length for our input tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 581
    },
    "id": "sc9oNJ75KZwZ",
    "outputId": "297bd40e-a400-47df-dcd4-9c652120ccd6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_data_lengths(tokenized_ingredients, tokenized_instructions):\n",
    "    lengths = [len(x['input_ids']) for x in tokenized_titles]\n",
    "    lengths += [len(x['input_ids']) for x in tokenized_ingredients]\n",
    "    print(len(lengths))\n",
    "\n",
    "    # Plotting the histogram\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(lengths, bins=20, alpha=0.7, color='blue')\n",
    "    plt.xlabel('Length of input_ids')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Distribution of Lengths of input_ids')\n",
    "    plt.show()\n",
    "\n",
    "plot_data_lengths(tokenized_ingredients, tokenized_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "ZbTte5073fEL"
   },
   "outputs": [],
   "source": [
    "max_length = 365  # This was an appropriate max length for my dataset\n",
    "\n",
    "def generate_and_tokenize_prompt2(ingredients, title, instructions):\n",
    "\n",
    "    ingredients_result = tokenizer(\n",
    "        ingredients,\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    title_result = tokenizer(\n",
    "        title,\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    instructions_result = tokenizer(\n",
    "        instructions,\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    ingredients_result[\"labels\"] = ingredients_result[\"input_ids\"].copy()\n",
    "    title_result[\"labels\"] = title_result[\"input_ids\"].copy()\n",
    "    instructions_result[\"labels\"] = title_result[\"input_ids\"].copy()\n",
    "\n",
    "    return ingredients_result, title_result, instructions_result\n",
    "\n",
    "# Tokenization of the dataset\n",
    "tokenized_data = []\n",
    "for ingredients, title, instructions in zip(df_ar['ingredients'].iloc[:5000], df_ar['title'].iloc[:5000], df_ar['instructions'].iloc[:5000]):\n",
    "    ingredients_result, title_result, instructions_result = generate_and_tokenize_prompt2(ingredients, title, instructions)\n",
    "    # Concatenating results into a single input\n",
    "    combined_input_ids = ingredients_result[\"input_ids\"] + title_result[\"input_ids\"] + instructions_result[\"input_ids\"]\n",
    "    combined_labels = ingredients_result[\"labels\"] + title_result[\"labels\"] +  instructions_result[\"labels\"]\n",
    "    tokenized_data.append({'input_ids': combined_input_ids, 'labels': combined_labels})\n",
    "\n",
    "# Split data into training and evaluation datasets\n",
    "split_index = int(0.8 * len(tokenized_data))\n",
    "train_dataset = tokenized_data[:split_index]\n",
    "eval_dataset = tokenized_data[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fke7hj1JPyQT",
    "outputId": "5e5ca835-3aa1-4af6-9950-e7481f0c856b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Ingredients: brown sugar , sea salt , paprika , ground black pepper , onion powder , garlic powder , ground cumin , dried sage , crushed red pepper, or to taste , chili powder, or to taste , dried thyme, or to taste ,\n",
      "### Generate Title and Instructions:\n",
      "### Title: Brown Sugar Rubbed Pork Chops\n",
      "### Instructions:\n",
      "1. In a small bowl, mix together the brown sugar, sea salt, paprika, black pepper, onion powder, garlic powder, cumin, sage, red pepper flakes, chili powder, thyme, and oregano until well blended.\n",
      "2. Place pork chops in a shallow dish and sprinkle both sides with rub mixture. Cover and refrigerate for at least 30 minutes.\n",
      "3. Preheat an outdoor grill for medium-high heat and lightly oil the grate.\n",
      "4. Grill pork chops for 5 to 7 minutes per side, or until no longer pink in the center and the juices run clear. An instant-read thermometer inserted into the center should read at least 145 degrees F (63 degrees C).\n"
     ]
    }
   ],
   "source": [
    "eval_prompt = f\"### Ingredients: {df_ar['ingredients'].iloc[24367]}\\n### Generate Title and Instructions:\\n### Title:\"\n",
    "\n",
    "# Init an eval tokenizer that doesn't add padding or eos token\n",
    "eval_tokenizer = AutoTokenizer.from_pretrained(\n",
    "    base_model_id,\n",
    "    add_bos_token=True,\n",
    ")\n",
    "\n",
    "model_input = eval_tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    print(eval_tokenizer.decode(model.generate(**model_input, max_new_tokens=256, repetition_penalty=1.15)[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k4qY_S0EaOPs"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JMDv9mCeV-il"
   },
   "source": [
    "**Set Up LoRA**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "txXs94_zWCcQ"
   },
   "source": [
    "Now, to start our fine-tuning, we have to apply some preprocessing to the model to prepare it for training. For that use the prepare_model_for_kbit_training method from PEFT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "k-rUo6KTWFMU"
   },
   "outputs": [],
   "source": [
    "from peft import prepare_model_for_kbit_training\n",
    "\n",
    "model.gradient_checkpointing_enable()\n",
    "model = prepare_model_for_kbit_training(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "JTws6uDbWIOD"
   },
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YMHP0xk-WNVV"
   },
   "source": [
    "Let's print the model to examine its layers, as we will apply QLoRA to all the linear layers of the model. Those layers are q_proj, k_proj, v_proj, o_proj, gate_proj, up_proj, down_proj, and lm_head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z-6Iqd0KYCID",
    "outputId": "a0569bd1-2358-4f92-c5f8-336286a831be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MistralForCausalLM(\n",
      "  (model): MistralModel(\n",
      "    (embed_tokens): Embedding(32000, 4096)\n",
      "    (layers): ModuleList(\n",
      "      (0-31): 32 x MistralDecoderLayer(\n",
      "        (self_attn): MistralSdpaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): MistralRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): MistralMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): MistralRMSNorm()\n",
      "        (post_attention_layernorm): MistralRMSNorm()\n",
      "      )\n",
      "    )\n",
      "    (norm): MistralRMSNorm()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d13VfHnQYHw5"
   },
   "source": [
    "Here we define the LoRA config.\n",
    "\n",
    "r is the rank of the low-rank matrix used in the adapters, which thus controls the number of parameters trained. A higher rank will allow for more expressivity, but there is a compute tradeoff.\n",
    "\n",
    "alpha is the scaling factor for the learned weights. The weight matrix is scaled by alpha/r, and thus a higher value for alpha assigns more weight to the LoRA activations.\n",
    "\n",
    "The values used in the QLoRA paper were r=64 and lora_alpha=16, and these are said to generalize well, but we will use r=32 and lora_alpha=64 so that we have more emphasis on the new fine-tuned data while also reducing computational complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yvugWrLvYPZU",
    "outputId": "ac8a27cb-5ca3-4d55-ba69-7a1418a6f90a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 85041152 || all params: 7326773248 || trainable%: 1.1606903765339511\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "config = LoraConfig(\n",
    "    r=32,\n",
    "    lora_alpha=64,\n",
    "    target_modules=[\n",
    "        \"q_proj\",\n",
    "        \"k_proj\",\n",
    "        \"v_proj\",\n",
    "        \"o_proj\",\n",
    "        \"gate_proj\",\n",
    "        \"up_proj\",\n",
    "        \"down_proj\",\n",
    "        \"lm_head\",\n",
    "    ],\n",
    "    bias=\"none\",\n",
    "    lora_dropout=0.05,  # Conventional\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, config)\n",
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4xhf8d0LYUdD"
   },
   "source": [
    "See how the model looks different now, with the LoRA adapters added:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v6y9Rys9YWey",
    "outputId": "95594d1f-6562-4cb6-a152-8da3f24cf272"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeftModelForCausalLM(\n",
      "  (base_model): LoraModel(\n",
      "    (model): MistralForCausalLM(\n",
      "      (model): MistralModel(\n",
      "        (embed_tokens): Embedding(32000, 4096)\n",
      "        (layers): ModuleList(\n",
      "          (0-31): 32 x MistralDecoderLayer(\n",
      "            (self_attn): MistralSdpaAttention(\n",
      "              (q_proj): lora.Linear(\n",
      "                (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (k_proj): lora.Linear(\n",
      "                (base_layer): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=1024, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (v_proj): lora.Linear(\n",
      "                (base_layer): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=1024, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (o_proj): lora.Linear(\n",
      "                (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (rotary_emb): MistralRotaryEmbedding()\n",
      "            )\n",
      "            (mlp): MistralMLP(\n",
      "              (gate_proj): lora.Linear(\n",
      "                (base_layer): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=14336, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (up_proj): lora.Linear(\n",
      "                (base_layer): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=14336, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (down_proj): lora.Linear(\n",
      "                (base_layer): Linear(in_features=14336, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=14336, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "              )\n",
      "              (act_fn): SiLU()\n",
      "            )\n",
      "            (input_layernorm): MistralRMSNorm()\n",
      "            (post_attention_layernorm): MistralRMSNorm()\n",
      "          )\n",
      "        )\n",
      "        (norm): MistralRMSNorm()\n",
      "      )\n",
      "      (lm_head): lora.Linear(\n",
      "        (base_layer): Linear(in_features=4096, out_features=32000, bias=False)\n",
      "        (lora_dropout): ModuleDict(\n",
      "          (default): Dropout(p=0.05, inplace=False)\n",
      "        )\n",
      "        (lora_A): ModuleDict(\n",
      "          (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "        )\n",
      "        (lora_B): ModuleDict(\n",
      "          (default): Linear(in_features=32, out_features=32000, bias=False)\n",
      "        )\n",
      "        (lora_embedding_A): ParameterDict()\n",
      "        (lora_embedding_B): ParameterDict()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tIu5yNhYaRmq"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nkBAVmb3ZZ6e"
   },
   "source": [
    "**TRAINING LoRA MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "PGTxRTgLZi_0"
   },
   "outputs": [],
   "source": [
    "if torch.cuda.device_count() > 1: # If more than 1 GPU\n",
    "    model.is_parallelizable = True\n",
    "    model.model_parallel = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "J4Nh-UgTZktM"
   },
   "outputs": [],
   "source": [
    "from accelerate import FullyShardedDataParallelPlugin, Accelerator\n",
    "from torch.distributed.fsdp.fully_sharded_data_parallel import FullOptimStateDictConfig, FullStateDictConfig\n",
    "\n",
    "fsdp_plugin = FullyShardedDataParallelPlugin(\n",
    "    state_dict_config=FullStateDictConfig(offload_to_cpu=True, rank0_only=False),\n",
    "    optim_state_dict_config=FullOptimStateDictConfig(offload_to_cpu=True, rank0_only=False),\n",
    ")\n",
    "\n",
    "accelerator = Accelerator(fsdp_plugin=fsdp_plugin)\n",
    "\n",
    "model = accelerator.prepare_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_QY-O7nOa3AZ",
    "outputId": "f4ace141-0cdd-431c-dabf-b9a490e52185"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmatteo-rambaldi\u001b[0m (\u001b[33mrecipes_model\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "!pip install -q wandb -U\n",
    "\n",
    "import wandb, os\n",
    "wandb.login()\n",
    "\n",
    "wandb_project = \"journal-finetune\"\n",
    "if len(wandb_project) > 0:\n",
    "    os.environ[\"WANDB_PROJECT\"] = wandb_project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 974
    },
    "id": "BeEHSdGmZyjQ",
    "outputId": "12c8bf03-2316-4a2a-c40d-96655b66fe2d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 34:10, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.112700</td>\n",
       "      <td>0.989065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.946800</td>\n",
       "      <td>0.959924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.966000</td>\n",
       "      <td>0.945103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.935600</td>\n",
       "      <td>0.930330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.939700</td>\n",
       "      <td>0.921595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.855100</td>\n",
       "      <td>0.914417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.825100</td>\n",
       "      <td>0.914595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.866600</td>\n",
       "      <td>0.908163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.873500</td>\n",
       "      <td>0.899783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.886400</td>\n",
       "      <td>0.895214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.830300</td>\n",
       "      <td>0.891957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.884300</td>\n",
       "      <td>0.886196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.856700</td>\n",
       "      <td>0.883677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.840700</td>\n",
       "      <td>0.882293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.803700</td>\n",
       "      <td>0.880434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.786400</td>\n",
       "      <td>0.879314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.839000</td>\n",
       "      <td>0.877612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.813200</td>\n",
       "      <td>0.875947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.856800</td>\n",
       "      <td>0.874848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.798200</td>\n",
       "      <td>0.874303</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=500, training_loss=0.8758536605834961, metrics={'train_runtime': 2055.5362, 'train_samples_per_second': 0.486, 'train_steps_per_second': 0.243, 'total_flos': 4.727575719936e+16, 'train_loss': 0.8758536605834961, 'epoch': 0.25})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from datetime import datetime\n",
    "import torch\n",
    "\n",
    "project = \"recepies-model_v5\"\n",
    "base_model_name = \"mistral\"\n",
    "run_name = base_model_name + \"-\" + project\n",
    "output_dir = \"./\" + run_name\n",
    "\n",
    "# Initialize Trainer with your model and tokenizer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=TrainingArguments(\n",
    "        output_dir='./output',\n",
    "        warmup_steps=1,\n",
    "        per_device_train_batch_size=2,\n",
    "        gradient_accumulation_steps=1,\n",
    "        gradient_checkpointing=True,\n",
    "        max_steps=500,\n",
    "        learning_rate=2.5e-5,\n",
    "        fp16=True,\n",
    "        optim=\"paged_adamw_8bit\",\n",
    "        logging_steps=25,\n",
    "        logging_dir=\"./logs\",\n",
    "        save_strategy=\"steps\",\n",
    "        save_steps=25,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        eval_steps=25,\n",
    "        do_eval=True,\n",
    "        report_to=\"wandb\",\n",
    "        run_name=f\"{run_name}-{datetime.now().strftime('%Y-%m-%d-%H-%M')}\"\n",
    "    ),\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
    ")\n",
    "model.config.use_cache = False\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17,
     "referenced_widgets": [
      "ccc1bd2c0a454f96bd2fc895043dde0f",
      "6c7723b53aa749cf93987e4e5fa1da32",
      "ce0066c99ea64879b679fb68afe2e47d",
      "3fc14a395f1d4569865cbeea819c42c6",
      "5f2a769a466e4c8ebed1b5eb555390cb",
      "9b238e7f08264805b524ac3100444476",
      "7afe9062140a45099f85e96d07db9a27",
      "ed6210d9752348ab9478e527c28c3c2b",
      "3c8da0d7d977480daec405cbd81ce475",
      "f711cc2c2590496eb21e79a64e16660f",
      "e3eb380a732c4ac4aa897968f546f1c8"
     ]
    },
    "id": "2pHEKwMW4Y9K",
    "outputId": "3cdba9a4-bb89-4043-b33b-f99d7aeadcaf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b03167d26b941b9baed696562e56fa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nbnb_config = BitsAndBytesConfig(\\n    load_in_4bit=True,\\n    bnb_4bit_use_double_quant=True,\\n    bnb_4bit_quant_type=\"nf4\",\\n    bnb_4bit_compute_dtype=torch.bfloat16\\n)\\n\\nbase_model = AutoModelForCausalLM.from_pretrained(\\n    base_model_id,  # Mistral, same as before\\n    quantization_config=bnb_config,  # Same quantization config as before\\n    device_map=\"auto\",\\n    trust_remote_code=True,\\n)\\n\\neval_tokenizer = AutoTokenizer.from_pretrained(base_model_id, add_bos_token=True, trust_remote_code=True)\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "base_model_id = \"mistralai/Mistral-7B-v0.1\"\n",
    "\n",
    "# Load the model using the NVIDIA H100 GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = AutoModelForCausalLM.from_pretrained(base_model_id)\n",
    "model.to(device)  # Move model to GPU\n",
    "\n",
    "# Load tokenizer and configure with additional settings as needed\n",
    "eval_tokenizer = AutoTokenizer.from_pretrained(base_model_id, add_bos_token=True, trust_remote_code=True)\n",
    "'''\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_id,  # Mistral, same as before\n",
    "    quantization_config=bnb_config,  # Same quantization config as before\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "eval_tokenizer = AutoTokenizer.from_pretrained(base_model_id, add_bos_token=True, trust_remote_code=True)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "lUMWQkXD4Z3N"
   },
   "outputs": [],
   "source": [
    "from peft import PeftModel\n",
    "\n",
    "ft_model = PeftModel.from_pretrained(model, \"output/checkpoint-500\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mwm1UxK68tdE",
    "outputId": "812b5fb1-5bee-4c50-bad1-058b55fd7164"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Ingredients: 4 cooked chicken breasts, shredded , 2 Granny Smith apples, cut into small chunks , 2 cups chopped walnuts, or to taste , 1/2 red onion, chopped , 3 stalks celery, chopped , 3 tablespoons lemon juice , 1/2 cup vanilla yogurt , 5 tablespoons creamy salad dressing (such as Miracle Whip®) , 5 tablespoons mayonnaise , 25 seedless red grapes, halved , \n",
      "### Generate Title and Instructions:\n",
      "### Title: Chicken Waldorf Salad\n",
      "\n",
      "Preheat oven to 375 degrees F (190 degrees C). Place chicken in a baking dish. Bake until no longer pink in the center and juices run clear, about 30 minutes. Remove from heat, cool slightly, then shred with two forks.\n",
      "\n",
      "Place apples, walnuts, red onion, and celery in a large bowl; toss together. Add chicken, lemon juice,\n"
     ]
    }
   ],
   "source": [
    "eval_prompt = f\"### Ingredients: {df_ar['ingredients'].iloc[12369]}\\n### Generate Title and Instructions:\\n### Title:\"\n",
    "\n",
    "model_input = eval_tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "ft_model.eval()\n",
    "with torch.no_grad():\n",
    "    generated_texts = eval_tokenizer.decode(ft_model.generate(**model_input, max_new_tokens=100, repetition_penalty=1.15)[0], skip_special_tokens=True)\n",
    "    print(generated_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "obaG_MZzuOvr"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rouge_score in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (0.1.2)\n",
      "Requirement already satisfied: nltk in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from rouge_score) (3.8.1)\n",
      "Requirement already satisfied: absl-py in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from rouge_score) (2.1.0)\n",
      "Requirement already satisfied: numpy in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from rouge_score) (1.26.4)\n",
      "Requirement already satisfied: six>=1.14.0 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from rouge_score) (1.16.0)\n",
      "Requirement already satisfied: click in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from nltk->rouge_score) (8.1.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from nltk->rouge_score) (2024.4.28)\n",
      "Requirement already satisfied: tqdm in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from nltk->rouge_score) (4.66.4)\n",
      "Requirement already satisfied: joblib in /home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from nltk->rouge_score) (1.4.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_98613/66953692.py:6: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  bleu_metric = load_metric('bleu')\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/datasets/load.py:759: FutureWarning: The repository for bleu contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.1/metrics/bleu/bleu.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/datasets/load.py:759: FutureWarning: The repository for rouge contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.1/metrics/rouge/rouge.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.pyenv/versions/3.10.14/lib/python3.10/site-packages/datasets/load.py:759: FutureWarning: The repository for meteor contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.1/metrics/meteor/meteor.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "[nltk_data] Downloading package wordnet to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install rouge_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def evaluate_and_plot(generated_text, reference_text):\n",
    "    from datasets import load_metric\n",
    "    bleu_metric = load_metric('bleu')\n",
    "    rouge_metric = load_metric('rouge')\n",
    "    meteor_metric = load_metric('meteor')\n",
    "\n",
    "    predictions = [generated_text.split()]\n",
    "    references = [[reference_text.split()]]\n",
    "\n",
    "    # Compute metrics\n",
    "    bleu_result = bleu_metric.compute(predictions=predictions, references=references)['bleu']\n",
    "    rouge_result = rouge_metric.compute(predictions=[generated_text], references=[reference_text])['rouge1'].mid.fmeasure\n",
    "    meteor_result = meteor_metric.compute(predictions=[generated_text], references=[reference_text])['meteor']\n",
    "\n",
    "    # Prepare data for plotting\n",
    "    metrics = ['BLEU', 'ROUGE-1', 'METEOR']\n",
    "    scores = [bleu_result, rouge_result, meteor_result]\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.bar(metrics, scores, color=['blue', 'green', 'red'])\n",
    "    plt.xlabel('Metrics')\n",
    "    plt.ylabel('Scores')\n",
    "    plt.title('Evaluation Metrics')\n",
    "    plt.ylim(0, 1)  # Assuming the scores are normalized between 0 and 1\n",
    "    plt.show()\n",
    "\n",
    "# Example generated and reference texts\n",
    "reference_texts = f\"### Ingredients: {df_ar['ingredients'].iloc[12369]}\\n### Generate Title and Instructions:\\n### Title:{df_ar['title'].iloc[12369]}\\n### Instructions: {df_ar['instructions'].iloc[12369]}\"\n",
    "\n",
    "# Generate plot\n",
    "evaluate_and_plot(generated_texts, reference_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "include_colab_link": true,
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "23e56508698148a396955a35b8feb7da": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "HTMLStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "HTMLStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "StyleView",
      "background": null,
      "description_width": "",
      "font_size": null,
      "text_color": null
     }
    },
    "2d7614b2f7164f63bd78dc5de95ea1ff": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "2.0.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "2.0.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border_bottom": null,
      "border_left": null,
      "border_right": null,
      "border_top": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3c8da0d7d977480daec405cbd81ce475": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3fc14a395f1d4569865cbeea819c42c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "2.0.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_allow_html": false,
      "layout": "IPY_MODEL_f711cc2c2590496eb21e79a64e16660f",
      "placeholder": "​",
      "style": "IPY_MODEL_e3eb380a732c4ac4aa897968f546f1c8",
      "tabbable": null,
      "tooltip": null,
      "value": " 2/2 [00:56&lt;00:00, 26.61s/it]"
     }
    },
    "58c64e0d7d764deb9a80ee6ab8a0be95": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "2.0.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "2.0.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border_bottom": null,
      "border_left": null,
      "border_right": null,
      "border_top": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5f2a769a466e4c8ebed1b5eb555390cb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "2.0.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "2.0.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border_bottom": null,
      "border_left": null,
      "border_right": null,
      "border_top": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6640c21d6b354e1fb37300e965bd062d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "2.0.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_allow_html": false,
      "layout": "IPY_MODEL_efdb470c4faf447e8fb73326da34a641",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8688af750cff4c9885fdf03c322b579b",
      "tabbable": null,
      "tooltip": null,
      "value": 2
     }
    },
    "6c7723b53aa749cf93987e4e5fa1da32": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "2.0.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_allow_html": false,
      "layout": "IPY_MODEL_9b238e7f08264805b524ac3100444476",
      "placeholder": "​",
      "style": "IPY_MODEL_7afe9062140a45099f85e96d07db9a27",
      "tabbable": null,
      "tooltip": null,
      "value": "Loading checkpoint shards: 100%"
     }
    },
    "7afe9062140a45099f85e96d07db9a27": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "HTMLStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "HTMLStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "StyleView",
      "background": null,
      "description_width": "",
      "font_size": null,
      "text_color": null
     }
    },
    "80b02623217c4864a5802c1215d92f5a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "2.0.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "2.0.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border_bottom": null,
      "border_left": null,
      "border_right": null,
      "border_top": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8688af750cff4c9885fdf03c322b579b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "908522ef9bd94e6f8a02e4642ee38a0c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "2.0.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d8ce7a5f583f4fb7948614b68fd31404",
       "IPY_MODEL_6640c21d6b354e1fb37300e965bd062d",
       "IPY_MODEL_f24c5e848078403db2719e2c13c26f3d"
      ],
      "layout": "IPY_MODEL_58c64e0d7d764deb9a80ee6ab8a0be95",
      "tabbable": null,
      "tooltip": null
     }
    },
    "9b238e7f08264805b524ac3100444476": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "2.0.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "2.0.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border_bottom": null,
      "border_left": null,
      "border_right": null,
      "border_top": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a32c582e23e44efb86d9ab2203e7525f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "HTMLStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "HTMLStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "StyleView",
      "background": null,
      "description_width": "",
      "font_size": null,
      "text_color": null
     }
    },
    "ccc1bd2c0a454f96bd2fc895043dde0f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "2.0.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6c7723b53aa749cf93987e4e5fa1da32",
       "IPY_MODEL_ce0066c99ea64879b679fb68afe2e47d",
       "IPY_MODEL_3fc14a395f1d4569865cbeea819c42c6"
      ],
      "layout": "IPY_MODEL_5f2a769a466e4c8ebed1b5eb555390cb",
      "tabbable": null,
      "tooltip": null
     }
    },
    "ce0066c99ea64879b679fb68afe2e47d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "2.0.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_allow_html": false,
      "layout": "IPY_MODEL_ed6210d9752348ab9478e527c28c3c2b",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3c8da0d7d977480daec405cbd81ce475",
      "tabbable": null,
      "tooltip": null,
      "value": 2
     }
    },
    "d8ce7a5f583f4fb7948614b68fd31404": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "2.0.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_allow_html": false,
      "layout": "IPY_MODEL_80b02623217c4864a5802c1215d92f5a",
      "placeholder": "​",
      "style": "IPY_MODEL_a32c582e23e44efb86d9ab2203e7525f",
      "tabbable": null,
      "tooltip": null,
      "value": "Loading checkpoint shards: 100%"
     }
    },
    "e3eb380a732c4ac4aa897968f546f1c8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "HTMLStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "HTMLStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "StyleView",
      "background": null,
      "description_width": "",
      "font_size": null,
      "text_color": null
     }
    },
    "ed6210d9752348ab9478e527c28c3c2b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "2.0.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "2.0.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border_bottom": null,
      "border_left": null,
      "border_right": null,
      "border_top": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "efdb470c4faf447e8fb73326da34a641": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "2.0.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "2.0.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border_bottom": null,
      "border_left": null,
      "border_right": null,
      "border_top": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f24c5e848078403db2719e2c13c26f3d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "2.0.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_allow_html": false,
      "layout": "IPY_MODEL_2d7614b2f7164f63bd78dc5de95ea1ff",
      "placeholder": "​",
      "style": "IPY_MODEL_23e56508698148a396955a35b8feb7da",
      "tabbable": null,
      "tooltip": null,
      "value": " 2/2 [00:08&lt;00:00,  3.98s/it]"
     }
    },
    "f711cc2c2590496eb21e79a64e16660f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "2.0.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "2.0.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border_bottom": null,
      "border_left": null,
      "border_right": null,
      "border_top": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
